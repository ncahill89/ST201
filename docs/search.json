[
  {
    "objectID": "0-Information.html#information",
    "href": "0-Information.html#information",
    "title": "ST201 Module Information",
    "section": "Information",
    "text": "Information\n🏢 Office: Room 223, Logic House\n📧 Email: niamh.cahill@mu.ie\n📅 Lectures:\n\n📍Tuesdays @3pm in Physics Hall\n📍Thursdays @12pm in Physics Hall\n\n📚 Tutorials: Alternating weeks, beginning Week 4 (13th Oct).\n\n📍 Mondays 2pm in GFLAB\n📍 Tuesdays 11am, 1pm in GFLAB"
  },
  {
    "objectID": "0-Information.html#information-1",
    "href": "0-Information.html#information-1",
    "title": "ST201 Module Information",
    "section": "Information",
    "text": "Information\n📝 Assessment:\n\n4 Assignments worth 15%\n1 Midterm worth 10% (November 11th @ 3pm)\nFinal Exam worth 75% (January 9th @ 10am-12pm)\n\n📖 Textbooks:\n\nIntroduction to Statistical and Data Analysis by Christian Heimann & Michael Schomaker Shalabh\n\n⏰ Office Hours: By appointment (and please do make an appointment if needed)"
  },
  {
    "objectID": "0-Information.html#lecturing-format",
    "href": "0-Information.html#lecturing-format",
    "title": "ST201 Module Information",
    "section": "Lecturing format",
    "text": "Lecturing format\n\nLecture notes will be shared, but don’t hesitate to take your own notes for deeper understanding. 📝\nSlide links will be uploaded to Moodle for easy access after class. 💻\nExpect a mix of formats! Some lectures will focus on slides, while others will involve hands-on R coding in RStudio - a key part of this course. 💡💻\nRelevant R code will be provided to enhance your learning. 📊💻\nGot questions? Don’t be shy—ask them during the lecture! 🙋‍♂️🙋‍♀️"
  },
  {
    "objectID": "0-Information.html#what-topics-will-we-cover",
    "href": "0-Information.html#what-topics-will-we-cover",
    "title": "ST201 Module Information",
    "section": "What Topics Will We Cover?",
    "text": "What Topics Will We Cover?\nThe objective of this module is to introduce students to the fundamentals of Data Analysis using R. This course will cover (but is not limited to) the following topics:\n\n📊 Numerical and graphical data summaries\n📈 Measures of central tendency\n🔗 Association of two or more variables\n🤝 Correlation\n📉 Regression"
  },
  {
    "objectID": "0-Information.html#diversity-inclusion",
    "href": "0-Information.html#diversity-inclusion",
    "title": "ST201 Module Information",
    "section": "Diversity & inclusion",
    "text": "Diversity & inclusion\nIt is my intent to present materials and activities that are respectful of diversity: gender identity, sexuality, disability, age, socioeconomic status, ethnicity, race, nationality, religion, and culture. I may not always get this right so please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nTo help with this:\n\nIf you have a name that differs from those that appear in your official University records, please let me know!\nPlease let me know your preferred pronouns if you wish to do so.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Data Analysis!",
    "section": "",
    "text": "Welcome to the course website for ST201 Data Analysis!\nModule information\nLecture material (slides, notes, videos) are licensed under CC-BY-NC 4.0.\nContact: Niamh Cahill (niamh.cahill@mu.ie)"
  },
  {
    "objectID": "1-Data.html#data-basics",
    "href": "1-Data.html#data-basics",
    "title": "ST201 Data Analysis",
    "section": "Data basics",
    "text": "Data basics\n\nLoans DataDataset\n\n\nWe will consider a dataset with information for 50 loans\n\nEach row in the dataset represents a single loan\n\nformally, an observational unit\n\nEach column represents characteristics associated with the loan\n\nformally, a variable"
  },
  {
    "objectID": "1-Data.html#variables",
    "href": "1-Data.html#variables",
    "title": "ST201 Data Analysis",
    "section": "Variables",
    "text": "Variables\nObservations or data points can be collected in a statistical variable.\n\n\nQualitative Variables\nDescriptive or categorical variables that define characteristics.\n\n\n🌎 US State: Identifies geographic locations.\n🏷️ Loan Grade: Categorizes the quality of loans.\n🏠 Homeownership: Indicates property ownership status.\n\n\n\nQuantitative Variables\nMeasurable or numerical variables that quantify data.\n\n\n💵 Loan Amount: The total value of the loan.\n📈 Interest Rate: The cost of borrowing expressed as a percentage.\n🗓️ Loan Term: The duration for repayment.\n💰 Total Income: The amount of income earned."
  },
  {
    "objectID": "1-Data.html#variables-1",
    "href": "1-Data.html#variables-1",
    "title": "ST201 Data Analysis",
    "section": "Variables",
    "text": "Variables\nVariables can be categorized as either discrete or continuous.\n\n\nDiscrete Variables\nDistinct and countable variables that represent individual values.\n\n\n📅 Loan Term: The number of periods for repayment.\n🏷️ Loan Grade: Categories such as 1 = A, 2 = B, 3 = C, 4 = D…\n\n\n\nContinuous Variables\nVariables that can take an infinite number of values, representing measurable quantities.\n\n\n💵 Loan Amount: The exact value of the loan.\n📈 Interest Rate: The precise percentage of borrowing cost."
  },
  {
    "objectID": "1-Data.html#scales",
    "href": "1-Data.html#scales",
    "title": "ST201 Data Analysis",
    "section": "Scales",
    "text": "Scales\nUnderstanding the different scales of measurement helps in analyzing data accurately.\n\n\nNominal Scale\nValues cannot be ordered and represent distinct categories.\n\n\n🌎 US State: Identifies states without any order.\n🏠 Homeownership: Categories (rent, mortgage), with no inherent ranking.\n\n\n\nOrdinal Scale\nValues can be ordered and reflect a natural ranking.\n\n\n🎓 Loan Grade: Categories like A, B, C, D, E, which represent a quality spectrum."
  },
  {
    "objectID": "1-Data.html#grouped-data",
    "href": "1-Data.html#grouped-data",
    "title": "ST201 Data Analysis",
    "section": "Grouped Data",
    "text": "Grouped Data\nSometimes, data is available only in summarized form, where you know the category or group rather than the exact value.\n\n\nIncome Groups: (0 EUR - 20,000 EUR), [20,000 EUR - 30,000 EUR), etc.\nPolitical Parties: Combines parties with a low number of voters into one category (“other”).\nInsurance Claims: Claims data might be simplified - if a customer has made a claim or not (Yes/No)\nAny grouped variable with only two possible values is called a binary variable."
  },
  {
    "objectID": "1-Data.html#creating-data-sets",
    "href": "1-Data.html#creating-data-sets",
    "title": "ST201 Data Analysis",
    "section": "Creating Data Sets",
    "text": "Creating Data Sets\nA data frame is a convenient and common way to organize data, especially if collecting data in a spreadsheet.\n\n\nThe loan data is an example of a data frame.\nA data frame where each row is a unique case (observational unit), each column is a variable, and each cell is a single value is commonly referred to as tidy data.\nWhen recording data, use a tidy data frame unless you have a very good reason to use a different structure.\nThis structure allows new cases to be added as rows or new variables as new columns and facilitates visualization, summarization, and other statistical analyses."
  },
  {
    "objectID": "1-Data.html#statistical-software",
    "href": "1-Data.html#statistical-software",
    "title": "ST201 Data Analysis",
    "section": "Statistical Software",
    "text": "Statistical Software\nThere are number of statistical software packages which allow data collection, management, and–most importantly–analysis.\n\n\nWe will focus on the statistical software package R.\n\nData can easily be read into R to be analysed."
  },
  {
    "objectID": "1-Data.html#numerical-representations-of-categorical-data",
    "href": "1-Data.html#numerical-representations-of-categorical-data",
    "title": "ST201 Data Analysis",
    "section": "Numerical representations of categorical data",
    "text": "Numerical representations of categorical data\nLet’s consider the number (frequency) of loans made among renters vs mortgage holders vs those who own their home outright in this dataset\n\nFrequency TableCode\n\n\n\n\n\n\n\n.\nFreq\n\n\n\n\nrent\n21\n\n\nmortgage\n26\n\n\nown\n3\n\n\n\n\n\n\n\n\n\nhome &lt;- loan50$homeownership\nloan_tab &lt;- table(home)\nloan_tab\n\n\nhome\n    rent mortgage      own \n      21       26        3"
  },
  {
    "objectID": "1-Data.html#numerical-representations-of-categorical-data-1",
    "href": "1-Data.html#numerical-representations-of-categorical-data-1",
    "title": "ST201 Data Analysis",
    "section": "Numerical Representations of categorical Data",
    "text": "Numerical Representations of categorical Data\nLet’s consider the proportion (relative frequency) of loans made within each homeowner category in this dataset\n\nRelative Frequency TableCode\n\n\n\n\n\n\n\nhome\nFreq\n\n\n\n\nrent\n0.42\n\n\nmortgage\n0.52\n\n\nown\n0.06\n\n\n\n\n\n\n\n\n\nN &lt;- nrow(loan50)\nhome &lt;- loan50$homeownership\nloan_tab &lt;- table(home)\nloan_tab/N\n\n\nhome\n    rent mortgage      own \n    0.42     0.52     0.06"
  },
  {
    "objectID": "1-Data.html#graphical-representations-of-categorical-data",
    "href": "1-Data.html#graphical-representations-of-categorical-data",
    "title": "ST201 Data Analysis",
    "section": "Graphical representations of categorical data",
    "text": "Graphical representations of categorical data\nLet’s consider the number (frequency) of loans made among renters vs mortgage holders vs those who own their home outright in this dataset\n\nBarplotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhome &lt;- loan50$homeownership\nloan_tab &lt;- table(home)\nbarplot(loan_tab)"
  },
  {
    "objectID": "1-Data.html#graphical-representations-of-categorical-data-1",
    "href": "1-Data.html#graphical-representations-of-categorical-data-1",
    "title": "ST201 Data Analysis",
    "section": "Graphical representations of categorical data",
    "text": "Graphical representations of categorical data\nLet’s consider the proportion (relative frequency) of loans made within each homeowner category in this dataset\n\nBarplotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN &lt;- nrow(loan50)\nhome &lt;- loan50$homeownership\nloan_tab &lt;- table(home)\nbarplot(loan_tab/N)"
  },
  {
    "objectID": "1-Data.html#numerical-representations-of-numerical-data",
    "href": "1-Data.html#numerical-representations-of-numerical-data",
    "title": "ST201 Data Analysis",
    "section": "Numerical representations of numerical data",
    "text": "Numerical representations of numerical data\nConsider the frequencies of the unique loan amounts in the data:\n\n\n\n 3000  4400  4500  5000  5825  6000  6400  6500  7000  7500  9000 10000 12000 \n    2     1     1     1     1     4     1     1     1     1     1     2     1 \n12800 13125 13500 14500 15000 16000 16500 17000 18000 18200 18500 20000 22000 \n    1     1     1     1     3     1     1     1     2     1     1     3     1 \n24000 25000 29400 30000 32000 35000 38500 40000 \n    2     3     1     2     1     2     1     2 \n\n\n\n\nThere are 34 unique loan amounts.\nDoes it make sense to tabulate this type of data?"
  },
  {
    "objectID": "1-Data.html#graphical-representations-of-numerical-data",
    "href": "1-Data.html#graphical-representations-of-numerical-data",
    "title": "ST201 Data Analysis",
    "section": "Graphical representations of numerical data",
    "text": "Graphical representations of numerical data\n\nHistogramCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhist(loan50$loan_amount,\n     breaks = 34,\n     main = \"Histogram\",\n     xlab = \"Loan Amounts\")"
  },
  {
    "objectID": "1-Data.html#graphical-representations-of-numerical-data-1",
    "href": "1-Data.html#graphical-representations-of-numerical-data-1",
    "title": "ST201 Data Analysis",
    "section": "Graphical representations of numerical data",
    "text": "Graphical representations of numerical data\n\nHistogramCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhist(loan50$loan_amount,\n     breaks = 16,\n     main = \"Histogram\",\n     xlab = \"Loan Amounts\")"
  },
  {
    "objectID": "1-Data.html#graphical-representations-of-numerical-data-2",
    "href": "1-Data.html#graphical-representations-of-numerical-data-2",
    "title": "ST201 Data Analysis",
    "section": "Graphical representations of numerical data",
    "text": "Graphical representations of numerical data\n\nHistogramCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhist(loan50$loan_amount,\n     breaks = 8,\n     main = \"Histogram\",\n     xlab = \"Loan Amounts\")"
  },
  {
    "objectID": "1-Data.html#empirical-cumulative-distribution-function-ecdf",
    "href": "1-Data.html#empirical-cumulative-distribution-function-ecdf",
    "title": "ST201 Data Analysis",
    "section": "Empirical Cumulative Distribution Function (ECDF)",
    "text": "Empirical Cumulative Distribution Function (ECDF)\nConsider the following 10 loan amounts:\n\n\n [1] 3000 3000 4400 4500 5000 5825 6000 6000 6000 6000\n\n\n\n\nAn ECDF can be used to obtain the relative frequencies for values contained in certain intervals, e.g., 0 - 3000, 3001 - 5000.\nFor the 10 loan amounts we can see that\n\n20% of the amounts are equal to or below 3000\n50% are equal to or below 5000\n100% are equal to or below 6000"
  },
  {
    "objectID": "1-Data.html#ecdf-plot-of-loan-amounts-subset-of-10",
    "href": "1-Data.html#ecdf-plot-of-loan-amounts-subset-of-10",
    "title": "ST201 Data Analysis",
    "section": "ECDF plot of loan amounts (subset of 10)",
    "text": "ECDF plot of loan amounts (subset of 10)"
  },
  {
    "objectID": "1-Data.html#ecdf-plot-of-loan-amounts-all-data",
    "href": "1-Data.html#ecdf-plot-of-loan-amounts-all-data",
    "title": "ST201 Data Analysis",
    "section": "ECDF plot of loan amounts (all data)",
    "text": "ECDF plot of loan amounts (all data)\n\nECDF PlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloan_amount &lt;- loan50$loan_amount\nplot.ecdf(loan_amount)"
  },
  {
    "objectID": "index.html#lecture-slides",
    "href": "index.html#lecture-slides",
    "title": "Welcome to Data Analysis!",
    "section": "Lecture Slides",
    "text": "Lecture Slides\n\nWeek 1\n1a. Data\n1b. Code lecture; check the Rstudio Sever for Week1_Data.R\n\n\nWeek 2\n2a. Numerical Data\n2b. Code lecture; check the Rstudio Sever for Week2_NumericalData.R\n\n\nWeek 3\n3a. Association between Categorical Variables\n3b. Code lecture; check the Rstudio Sever for Week3_Categorical.R\n\n\nWeek 4\n4a. Association between Categorical Variables (2)\n4b. Code lecture; check the Rstudio Sever for Week4_Categorical(2).R\n\n\nWeek 5\n5a. Association between Categorical Variables (3)\n5b. Code lecture; check the Rstudio Sever for Week5_Categorical(3).R\n\n\nWeek 6\n6a. Discrete Probability Distributions\n6b. Code lecture; check the Rstudio Sever for Week6_Discrete.R\n\n\nWeek 7\nMidterm exam week\n\n\nWeek 8\n8a. Continuous Probability Distributions\n8b. Code lecture; check the Rstudio Sever for Week8_Continuous.R\n\n\nWeek 9\n9a. Single Samples\n9b. Code lecture; check the Rstudio Sever for Week9_SingleSamples.R\n\n\nWeek 10\n10a. Inference for Means\n10b. Code lecture; check the Rstudio Sever for Week10_InferenceMeans.R\n\n\nWeek 11\n11a. Simple Linear Regression\n11b. Code lecture; check the Rstudio Sever for Week11_SLR.R"
  },
  {
    "objectID": "2-Numerical.html#watt-test-challenge-7-rounds",
    "href": "2-Numerical.html#watt-test-challenge-7-rounds",
    "title": "ST201 Data Analysis",
    "section": "🚴 Watt Test Challenge: 7 Rounds! 🚴",
    "text": "🚴 Watt Test Challenge: 7 Rounds! 🚴\n\n🏋️‍♂️ Goal: Achieve an average of 160 watts\n⏲️ Time: 2 minutes per round\n💡 Pro Tip: Adjust the resistance to push your wattage higher!"
  },
  {
    "objectID": "2-Numerical.html#the-average-mean",
    "href": "2-Numerical.html#the-average-mean",
    "title": "ST201 Data Analysis",
    "section": "The Average (Mean)",
    "text": "The Average (Mean)\nThe mean, often called the average, is a common way to measure the center of a distribution of data. For example, assume we have a watt value every second over a two minute period. To compute the mean watt value, we add up all the watt values and divide by 120.\n\n\nThe Sample Mean\n\na typical or central value in a set of numbers.\nFormula: the sum of all values divided by the total number of values\n\n\nNotation (general)\n\noften labeled \\(\\bar{x}\\)\nFormula: \\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\\)\n\n\nFor the 🚴 Watt Test 🚴 we know what we want the mean to be e.g., 160.\n🤔 Consider how many different ways we can generate that mean value in a two minute interval."
  },
  {
    "objectID": "2-Numerical.html#visualisation---dot-plots",
    "href": "2-Numerical.html#visualisation---dot-plots",
    "title": "ST201 Data Analysis",
    "section": "Visualisation - Dot plots",
    "text": "Visualisation - Dot plots\n\n\nSometimes we are interested in the distribution of a single variable.\n\nIn these cases, a dot plot provides the most basic of displays.\nA dot plot is a one-variable scatterplot;\nan example using 120 seconds of watt values is shown:"
  },
  {
    "objectID": "2-Numerical.html#visualisation---dot-plots-1",
    "href": "2-Numerical.html#visualisation---dot-plots-1",
    "title": "ST201 Data Analysis",
    "section": "Visualisation - Dot plots",
    "text": "Visualisation - Dot plots\n\n\nSometimes we are interested in the distribution of a single variable.\n\nIn these cases, a dot plot provides the most basic of displays.\nA dot plot is a one-variable scatterplot;\nan example using 120 seconds of watt values is shown:"
  },
  {
    "objectID": "2-Numerical.html#visualisation---dot-plots-2",
    "href": "2-Numerical.html#visualisation---dot-plots-2",
    "title": "ST201 Data Analysis",
    "section": "Visualisation - Dot plots",
    "text": "Visualisation - Dot plots\n\n\nWe could achieve a similar average in a different way:"
  },
  {
    "objectID": "2-Numerical.html#visualisation---dot-plots-3",
    "href": "2-Numerical.html#visualisation---dot-plots-3",
    "title": "ST201 Data Analysis",
    "section": "Visualisation - Dot plots",
    "text": "Visualisation - Dot plots\n\n\nWe could achieve a similar average in a different way:"
  },
  {
    "objectID": "2-Numerical.html#scatter-plots",
    "href": "2-Numerical.html#scatter-plots",
    "title": "ST201 Data Analysis",
    "section": "Scatter Plots",
    "text": "Scatter Plots\nWe could also consider visualising two variables here if we include the time aspect.\n\n\n\nConsider the following strategy:\n\nget a 160 watt average in a 2 minute interval\nhave a steady increase every 10 seconds"
  },
  {
    "objectID": "2-Numerical.html#scatter-plots-1",
    "href": "2-Numerical.html#scatter-plots-1",
    "title": "ST201 Data Analysis",
    "section": "Scatter Plots",
    "text": "Scatter Plots\nWe could also consider visualising two variables here if we include the time aspect.\n\n\n\nConsider the following strategy:\n\nget a 160 watt average in a 2 minute interval\nhave a steady increase every 10 seconds"
  },
  {
    "objectID": "2-Numerical.html#scatter-plots-2",
    "href": "2-Numerical.html#scatter-plots-2",
    "title": "ST201 Data Analysis",
    "section": "Scatter Plots",
    "text": "Scatter Plots\nWe can change the strategy and still maintain the same average.\n\n\n\nConsider the following strategy:\n\nget a 160 watt average in a 2 minute interval\nhave a longer period of 160 watts"
  },
  {
    "objectID": "2-Numerical.html#scatter-plots-3",
    "href": "2-Numerical.html#scatter-plots-3",
    "title": "ST201 Data Analysis",
    "section": "Scatter Plots",
    "text": "Scatter Plots\nWe can change the strategy and still maintain the same average.\n\n\n\nConsider the following strategy:\n\nget a 160 watt average in a 2 minute interval\nhave a longer period of 160 watts"
  },
  {
    "objectID": "2-Numerical.html#scatter-plots-4",
    "href": "2-Numerical.html#scatter-plots-4",
    "title": "ST201 Data Analysis",
    "section": "Scatter Plots",
    "text": "Scatter Plots\nWe can change the strategy and still maintain the same average.\n\n\n\nConsider the following strategy:\n\nget a 160 watt average in a 2 minute interval\nhave a steady decrease every 10 seconds"
  },
  {
    "objectID": "2-Numerical.html#example---loan-interest-rates",
    "href": "2-Numerical.html#example---loan-interest-rates",
    "title": "ST201 Data Analysis",
    "section": "Example - Loan Interest Rates",
    "text": "Example - Loan Interest Rates\nA dot plot of the (rounded) loan interest rate data is shown below:\n\nDot PlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstripchart(x=round(loan50$interest_rate), \n           method = \"stack\", \n           at = 0, cex = 2,\n           col = \"steelblue\",  pch = 19,\n           main = \"\", \n           xlab = \"Loan interest rates\", \n           ylab=\"\")"
  },
  {
    "objectID": "2-Numerical.html#example---loan-interest-rates-1",
    "href": "2-Numerical.html#example---loan-interest-rates-1",
    "title": "ST201 Data Analysis",
    "section": "Example - Loan Interest Rates",
    "text": "Example - Loan Interest Rates\nA histogram of the loan interest rate data is shown below:\n\nDot PlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhist(x=loan50$interest_rate,\n     breaks = 10,\n     col = \"steelblue\", \n     main = \"\",\n     xlab = \"Loan interest rates\", \n     ylab=\"\")"
  },
  {
    "objectID": "2-Numerical.html#mean-of-loan-interest-rates",
    "href": "2-Numerical.html#mean-of-loan-interest-rates",
    "title": "ST201 Data Analysis",
    "section": "Mean of Loan Interest Rates",
    "text": "Mean of Loan Interest Rates\nWhen working with data we often have a sample from a larger population.\n\nWe can calculate the mean for the sample: \\(\\bar{x}\\).\n\nBut the mean of the entire population has a special label: \\(\\mu\\).\n\nWhy don’t we always calculate \\(\\mu\\)?\n\nOften not feasible to measure the population mean precisely.\nInstead, we estimate \\(\\mu\\) using the sample mean \\(\\bar{x}\\).\n\nLoan Interest Rate Example\n\nFrom the sample of 50 loans, the mean interest rate is 11.57%.\n\nLater we’ll explore how reliable \\(\\bar{x}\\) is for estimating \\(\\mu\\)!"
  },
  {
    "objectID": "2-Numerical.html#later-well-explore-how-reliable-barx-is-in-estimating-mu",
    "href": "2-Numerical.html#later-well-explore-how-reliable-barx-is-in-estimating-mu",
    "title": "ST201 Data Analysis",
    "section": "Later we’ll explore how reliable \\(\\bar{x}\\) is in estimating \\(\\mu\\)!",
    "text": "Later we’ll explore how reliable \\(\\bar{x}\\) is in estimating \\(\\mu\\)!"
  },
  {
    "objectID": "2-Numerical.html#median---loan-interest-rates",
    "href": "2-Numerical.html#median---loan-interest-rates",
    "title": "ST201 Data Analysis",
    "section": "Median - Loan Interest Rates",
    "text": "Median - Loan Interest Rates\n\nThe median is the value which divides the observations into two equal parts\n\n\n\nThe Median\n\nthe 50th percentile.\nFormula: order the values and find the middle value\n\n\nNotation (general)\n\nlabeled \\(\\tilde{x}^{(0.5)}\\)\nFormula: \\[\n\\tilde{x}^{(0.5)} =\n\\begin{cases}\nx_{(n+1)/2},& \\text{if n is odd}\\\\\n\\frac{1}{2}(x_{n/2} + x_{(n/2) + 1}), & \\text{if n is even}\n\\end{cases}\\]\n\n\n\nConsider 10 interest rates from the loan data and calculate the median\n\n\n\n [1] 11 10 26 10  9 10 17  6  8 13"
  },
  {
    "objectID": "2-Numerical.html#median---loan-interest-rates-1",
    "href": "2-Numerical.html#median---loan-interest-rates-1",
    "title": "ST201 Data Analysis",
    "section": "Median - Loan Interest Rates",
    "text": "Median - Loan Interest Rates\n\nRecall the ECDF? Let’s look at it for the interest rate data and get an idea of where the median is.\n\n\nECDF PlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot.ecdf(x=loan50$interest_rate) \nabline(h = 0.5)"
  },
  {
    "objectID": "2-Numerical.html#quantiles",
    "href": "2-Numerical.html#quantiles",
    "title": "ST201 Data Analysis",
    "section": "Quantiles",
    "text": "Quantiles\n\nQuantiles are a generalization of the idea of the median\nA quantile partitions the data into proportions\nIn general a (\\(\\alpha \\times 100\\))% - quantile (percentile) splits the data such that at least (\\(\\alpha \\times 100\\))% of the values are \\(\\leq\\) the quantile value \\(\\tilde{x}^{(\\alpha)}\\).\n\\[\n  \\tilde{x}^{(\\alpha)} =\n\\begin{cases}\n  x_{(k)},& \\text{if } n\\alpha \\text{ is not an integer},\n  \\text{k = smallest integer &gt; } n\\alpha\\\\\n  \\frac{1}{2}(x_{n\\alpha} + x_{n\\alpha + 1}), & \\text{if } n\\alpha \\text{ is an integer}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "2-Numerical.html#quantiles-1",
    "href": "2-Numerical.html#quantiles-1",
    "title": "ST201 Data Analysis",
    "section": "Quantiles",
    "text": "Quantiles\n\nLet’s look at the ECDF for the interest rate data and get an idea of where the 80th percentile is."
  },
  {
    "objectID": "2-Numerical.html#measures-of-dispersion---range",
    "href": "2-Numerical.html#measures-of-dispersion---range",
    "title": "ST201 Data Analysis",
    "section": "Measures of Dispersion - Range",
    "text": "Measures of Dispersion - Range\n\nThe range is a measure of dispersion defined as the difference between the maximum and minimum value of the data.\nThe interquartile range is the difference between the 75% quantile (upper quartile) and 25% quantile (lower quartile).\n\nIt covers the center of the data distribution and contains 50% of the observations.\n\n\\[d_{Q} = \\tilde{x}^{(0.75)} - \\tilde{x}^{(0.25)}\\]"
  },
  {
    "objectID": "2-Numerical.html#boxplots",
    "href": "2-Numerical.html#boxplots",
    "title": "ST201 Data Analysis",
    "section": "Boxplots",
    "text": "Boxplots\nConsider a boxplot of the interest rates.\n\nBoxplotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboxplot(loan50$interest_rate,\n        ylab = \"Loan interest rates\")"
  },
  {
    "objectID": "2-Numerical.html#measures-of-dispersion---variance",
    "href": "2-Numerical.html#measures-of-dispersion---variance",
    "title": "ST201 Data Analysis",
    "section": "Measures of Dispersion - Variance",
    "text": "Measures of Dispersion - Variance\n\nAnother measure of dispersion is the variance. The variance is one of the most important measures in statistics.\n\nThis can be thought of as the mean of the squared errors\n\n\\[s^2 = \\frac{1}{n-1}\\sum_{i = 1}^{n}(x_i - \\bar{x})^2\\]\n\nthe variance of the interest rates in the loan dataset is 25.52\n\nthe standard deviation, \\(s\\), is 5.05"
  },
  {
    "objectID": "2-Numerical.html#robust-statistics",
    "href": "2-Numerical.html#robust-statistics",
    "title": "ST201 Data Analysis",
    "section": "Robust statistics",
    "text": "Robust statistics"
  },
  {
    "objectID": "2-Numerical.html#robust-statistics-1",
    "href": "2-Numerical.html#robust-statistics-1",
    "title": "ST201 Data Analysis",
    "section": "Robust statistics",
    "text": "Robust statistics"
  },
  {
    "objectID": "2-Numerical.html#robust-statistics-2",
    "href": "2-Numerical.html#robust-statistics-2",
    "title": "ST201 Data Analysis",
    "section": "Robust statistics",
    "text": "Robust statistics"
  },
  {
    "objectID": "2-Numerical.html#robust-statistics-3",
    "href": "2-Numerical.html#robust-statistics-3",
    "title": "ST201 Data Analysis",
    "section": "Robust statistics",
    "text": "Robust statistics"
  },
  {
    "objectID": "2-Numerical.html#scatterplots-for-paired-data",
    "href": "2-Numerical.html#scatterplots-for-paired-data",
    "title": "ST201 Data Analysis",
    "section": "Scatterplots for paired data",
    "text": "Scatterplots for paired data\nLoan amount vs Interest rates\n\nScatterplotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot(x=loan50$loan_amount, \n     y=loan50$interest_rate,\n     cex=2, \n     cex.lab = 1.5,\n     pch = 19, \n     col = \"steelblue\",\n     xlab = \"Loan amount (thousands)\", \n     ylab=\"Interest rates (%)\")"
  },
  {
    "objectID": "2-Numerical.html#scatterplots-for-paired-data-1",
    "href": "2-Numerical.html#scatterplots-for-paired-data-1",
    "title": "ST201 Data Analysis",
    "section": "Scatterplots for paired data",
    "text": "Scatterplots for paired data\nLoan amount vs Income"
  },
  {
    "objectID": "2-Numerical.html#scatterplots-for-paired-data-2",
    "href": "2-Numerical.html#scatterplots-for-paired-data-2",
    "title": "ST201 Data Analysis",
    "section": "Scatterplots for paired data",
    "text": "Scatterplots for paired data\nInterest rates vs Income"
  },
  {
    "objectID": "2-Numerical.html#scatter-plots-5",
    "href": "2-Numerical.html#scatter-plots-5",
    "title": "ST201 Data Analysis",
    "section": "Scatter Plots",
    "text": "Scatter Plots\nWe can change the strategy and still maintain the same average.\n\n\n\nConsider the following strategy:\n\nget a 160 watt average in a 2 minute interval\nhave a steady decrease every 10 seconds"
  },
  {
    "objectID": "2-Numerical.html#robust-statistics---mean-vs-median",
    "href": "2-Numerical.html#robust-statistics---mean-vs-median",
    "title": "ST201 Data Analysis",
    "section": "Robust statistics - Mean vs Median",
    "text": "Robust statistics - Mean vs Median\n\nred = mean\ngreen = median"
  },
  {
    "objectID": "2-Numerical.html#robust-statistics---mean-vs-median-1",
    "href": "2-Numerical.html#robust-statistics---mean-vs-median-1",
    "title": "ST201 Data Analysis",
    "section": "Robust statistics - Mean vs Median",
    "text": "Robust statistics - Mean vs Median\n\nred = mean\ngreen = median"
  },
  {
    "objectID": "2-Numerical.html#robust-statistics---mean-vs-median-2",
    "href": "2-Numerical.html#robust-statistics---mean-vs-median-2",
    "title": "ST201 Data Analysis",
    "section": "Robust statistics - Mean vs Median",
    "text": "Robust statistics - Mean vs Median"
  },
  {
    "objectID": "2-Numerical.html#robust-statistics---mean-vs-median-3",
    "href": "2-Numerical.html#robust-statistics---mean-vs-median-3",
    "title": "ST201 Data Analysis",
    "section": "Robust statistics - Mean vs Median",
    "text": "Robust statistics - Mean vs Median\n\nred = mean\ngreen = median"
  },
  {
    "objectID": "2-Numerical.html#changing-variances",
    "href": "2-Numerical.html#changing-variances",
    "title": "ST201 Data Analysis",
    "section": "Changing variances",
    "text": "Changing variances\nWhich histogram has s = 5, 10, 15, 20"
  },
  {
    "objectID": "2-Numerical.html#changing-variances-1",
    "href": "2-Numerical.html#changing-variances-1",
    "title": "ST201 Data Analysis",
    "section": "Changing variances",
    "text": "Changing variances\nWhich boxplot has s = 5, 10, 15, 20"
  },
  {
    "objectID": "2-Numerical.html#changing-variancesstandard-deviations",
    "href": "2-Numerical.html#changing-variancesstandard-deviations",
    "title": "ST201 Data Analysis",
    "section": "Changing variances/standard deviations",
    "text": "Changing variances/standard deviations\nWhich histogram has s = 5, 10, 15, 20"
  },
  {
    "objectID": "2-Numerical.html#changing-variancesstandard-deviations-1",
    "href": "2-Numerical.html#changing-variancesstandard-deviations-1",
    "title": "ST201 Data Analysis",
    "section": "Changing variances/standard deviations",
    "text": "Changing variances/standard deviations\nWhich boxplot has s = 5, 10, 15, 20"
  },
  {
    "objectID": "Tutorial1.html",
    "href": "Tutorial1.html",
    "title": "ST201 Tutorial Sheet 1",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 14th October 2024."
  },
  {
    "objectID": "Tutorial1.html#instructions",
    "href": "Tutorial1.html#instructions",
    "title": "ST201 Tutorial Sheet 1",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 14th October 2024."
  },
  {
    "objectID": "Tutorial1.html#reading-the-the-data",
    "href": "Tutorial1.html#reading-the-the-data",
    "title": "ST201 Tutorial Sheet 1",
    "section": "Reading the the Data",
    "text": "Reading the the Data\nOpen a new R script. The pizza delivery dataset is available on the Rstudio server in the ST201 folder in a file called pizza_del.rds. You can load the file into R by clicking the file and loading it in or copying the following code into your R script:\n\npizza_del &lt;- readRDS(\"~/SharedFiles/ST201/pizza_del.rds\")\n\nLet’s say we want to look at the distance variable (distance between the pizza place and the delivery location) in the pizza_del dataset. Copy the following into your R script and run it to view the first 10 observations of this variable:\n\npizza_del$distance[1:10]\n\nExercise 1\nWhat is the value of the 275th observation of distance?"
  },
  {
    "objectID": "Tutorial1.html#mean-and-median",
    "href": "Tutorial1.html#mean-and-median",
    "title": "ST201 Tutorial Sheet 1",
    "section": "Mean and Median",
    "text": "Mean and Median\nNow, suppose we are interested in the average distance between the pizza place and the delivery location. Copy the following into your R script and run it to to obtain the average:\n\nmean(pizza_del$distance)\n\nExercise 2\n\nUsing R, find the median distance between the pizza place and the delivery location.\nHow does the mean compare to the median? What might this tell you about the distribution of the data?"
  },
  {
    "objectID": "Tutorial1.html#quantiles",
    "href": "Tutorial1.html#quantiles",
    "title": "ST201 Tutorial Sheet 1",
    "section": "Quantiles",
    "text": "Quantiles\nNow I want to know what distance value represents the lower quartile (25% quantile) of the data. To do this I can use the quantile function in R. Copy the following into your R script. If you run this, you will notice an error, why?\n\nquantile(pizza_del$distance,)\n\n\nExercise 3\n\nAdd the correct argument to the quantile function for finding the 25% quantile.\n\nWhen you correct the code above and run it you will see that the lower quartile value is 1.3. So this means that there’s a 25% chance that the delivery driver will need to travel less than 1.3 km when delivering pizzas. Why might this information be useful to the owners of a pizza place?\n\nWhat is the upper quartile distance value?\nProvide an interpretation for (b)."
  },
  {
    "objectID": "Tutorial1.html#variance-and-standard-deviation",
    "href": "Tutorial1.html#variance-and-standard-deviation",
    "title": "ST201 Tutorial Sheet 1",
    "section": "Variance and Standard Deviation",
    "text": "Variance and Standard Deviation\nI want to know how much variation there is in the distances.\nExercise 4\n\nUse the var function in R to calculate the variance.\nUse R to obtain the standard deviation using the sd function. What is the advantage of using the standard deviation as a measure of variation?\nWhat range of distances fall within 1 standard deviation of the mean distance?"
  },
  {
    "objectID": "Tutorial1.html#boxplots-and-histograms",
    "href": "Tutorial1.html#boxplots-and-histograms",
    "title": "ST201 Tutorial Sheet 1",
    "section": "Boxplots and Histograms",
    "text": "Boxplots and Histograms\nI want to visualise the distance variable using a boxplot. Copy the following into your R script and run it to produce a boxplot:\n\nboxplot(pizza_del$distance)\n\nExercise 5\n\nAdd a y-axis label to the boxplot by adding a ylab argument to the code above. Label the axis “Distance (km)”\nProvide an interpretation for the boxplot.\n\nExercise 6\n\nCreate a histogram of the distance variable using the hist function. Change the x-axis label to “Distance (km)” using the argument xlab.\nDescribe the distribution of the histogram (symmetric or skewed?). What have you learned from this?\n\nSAVE YOUR R SCRIPT!\nClick: file - save as"
  },
  {
    "objectID": "index.html#tutorial-sheets",
    "href": "index.html#tutorial-sheets",
    "title": "Welcome to Data Analysis!",
    "section": "Tutorial Sheets",
    "text": "Tutorial Sheets\nTutorial Sheet 1: Numerical Data\nTutorial Sheet 2: Categorical Data\nTutorial Sheet 3: Discrete Distributions\nTutorial Sheet 4: Continous Distributions, CLT and Confidence Intervals"
  },
  {
    "objectID": "3-Categorical.html#association-of-two-variables",
    "href": "3-Categorical.html#association-of-two-variables",
    "title": "ST201 Data Analysis",
    "section": "Association of Two Variables",
    "text": "Association of Two Variables\nWe are often interested in the interdependence of two or more categorical variables\n\ne.g., we might be interested in whether the satisfaction of airline customers varies w.r.t the travel class (Economy, Business)\ne.g., we may want to find out of female employees at a company are paid less than male employees or vice versa. Assume in this example we have two salary categories (low, high).\n\nWhen both variables are categorical then it is possible to list all combinations of the variables and count how often the combinations occur in the data."
  },
  {
    "objectID": "3-Categorical.html#airline-satisfaction-example",
    "href": "3-Categorical.html#airline-satisfaction-example",
    "title": "ST201 Data Analysis",
    "section": "Airline Satisfaction Example",
    "text": "Airline Satisfaction Example\nSuppose we have data on two categorical variables.\n\n\n\n\n\nclass\nsatisfaction\n\n\n\n\nE\nfair\n\n\nE\nv. good\n\n\nE\npoor\n\n\nB\ngood\n\n\nE\npoor\n\n\nB\nfair\n\n\nE\ngood\n\n\nB\nv. good\n\n\nE\nfair\n\n\nB\nv. good\n\n\nE\ngood\n\n\nB\ngood"
  },
  {
    "objectID": "3-Categorical.html#contingency-tables",
    "href": "3-Categorical.html#contingency-tables",
    "title": "ST201 Data Analysis",
    "section": "Contingency Tables",
    "text": "Contingency Tables\nThis data can be described in a two-dimensional contingency table.\n\nContingency TableCode\n\n\n\n\n\n\n\n\npoor\nfair\ngood\nv. good\n\n\n\n\nB\n0\n1\n2\n2\n\n\nE\n2\n2\n2\n1\n\n\n\n\n\n\n\n\n\ntab &lt;- table(airline_subset)\ntab\n\n\n     satisfaction\nclass poor fair good v. good\n    B    0    1    2       2\n    E    2    2    2       1"
  },
  {
    "objectID": "3-Categorical.html#marginal-and-conditional-distributions",
    "href": "3-Categorical.html#marginal-and-conditional-distributions",
    "title": "ST201 Data Analysis",
    "section": "Marginal and Conditional Distributions",
    "text": "Marginal and Conditional Distributions\nAirline data; N = 100\n\n\n\n\n\n\npoor\nfair\ngood\nv. good\n\n\n\n\nB\n3\n3\n8\n14\n\n\nE\n12\n34\n15\n11\n\n\n\n\n\n\n\n\n\n\n\nMarginal frequency\n\n\nMarginal frequency distributions are displayed in the last column and last row.\n\n\n\n\n\n\n\n\n\nConditional frequency\n\n\nConditional frequency distributions give us an idea about the behaviour of one variable when the other one is kept fixed."
  },
  {
    "objectID": "3-Categorical.html#marginal-distributions",
    "href": "3-Categorical.html#marginal-distributions",
    "title": "ST201 Data Analysis",
    "section": "Marginal Distributions",
    "text": "Marginal Distributions\n\n\n\n\n\n\npoor\nfair\ngood\nv. good\n\n\n\n\nB\n3\n3\n8\n14\n\n\nE\n12\n34\n15\n11\n\n\n\n\n\n\nAdding the marginal frequencies to the tableCode\n\n\n\n\n\n\n\n\npoor\nfair\ngood\nv. good\nSum\n\n\n\n\nB\n3\n3\n8\n14\n28\n\n\nE\n12\n34\n15\n11\n72\n\n\nSum\n15\n37\n23\n25\n100\n\n\n\n\n\n\n\n\n\ntab &lt;- table(airline)\naddmargins(tab)\n\n\n     satisfaction\nclass poor fair good v. good Sum\n  B      3    3    8      14  28\n  E     12   34   15      11  72\n  Sum   15   37   23      25 100"
  },
  {
    "objectID": "3-Categorical.html#marginal-distributions-1",
    "href": "3-Categorical.html#marginal-distributions-1",
    "title": "ST201 Data Analysis",
    "section": "Marginal Distributions",
    "text": "Marginal Distributions\n\n\n\n\n\n\npoor\nfair\ngood\nv. good\n\n\n\n\nB\n3\n3\n8\n14\n\n\nE\n12\n34\n15\n11\n\n\n\n\n\n\nAdding the marginal relative frequencies to the tableCode\n\n\n\n\n\n\n\n\npoor\nfair\ngood\nv. good\nSum\n\n\n\n\nB\n0.03\n0.03\n0.08\n0.14\n0.28\n\n\nE\n0.12\n0.34\n0.15\n0.11\n0.72\n\n\nSum\n0.15\n0.37\n0.23\n0.25\n1.00\n\n\n\n\n\n\n\n\n\ntab &lt;- table(airline)\nrel_tab &lt;- prop.table(tab)\naddmargins(rel_tab)\n\n\n     satisfaction\nclass poor fair good v. good  Sum\n  B   0.03 0.03 0.08    0.14 0.28\n  E   0.12 0.34 0.15    0.11 0.72\n  Sum 0.15 0.37 0.23    0.25 1.00"
  },
  {
    "objectID": "3-Categorical.html#conditional-distributions",
    "href": "3-Categorical.html#conditional-distributions",
    "title": "ST201 Data Analysis",
    "section": "Conditional Distributions",
    "text": "Conditional Distributions\n\n\n\n\n\n\npoor\nfair\ngood\nv. good\n\n\n\n\nB\n3\n3\n8\n14\n\n\nE\n12\n34\n15\n11\n\n\n\n\n\n\nConditioning on classCode\n\n\nThe probability of satisfaction conditional on Business class\n\n\n     poor      fair      good   v. good \n0.1071429 0.1071429 0.2857143 0.5000000 \n\n\nThe probability of satisfaction conditional on Economy class\n\n\n     poor      fair      good   v. good \n0.1666667 0.4722222 0.2083333 0.1527778 \n\n\n\n\n\n\ntab &lt;- table(airline)\n\n# The probability of satisfaction conditional on Business class\ncond_prob_B &lt;- tab[1,]/sum(tab[1,])\n\n# The probability of satisfaction conditional on Economy class\ncond_prob_E &lt;- tab[2,]/sum(tab[2,])\n\ncond_prob_B; cond_prob_E\n\n\n     poor      fair      good   v. good \n0.1071429 0.1071429 0.2857143 0.5000000 \n\n\n     poor      fair      good   v. good \n0.1666667 0.4722222 0.2083333 0.1527778"
  },
  {
    "objectID": "3-Categorical.html#visualisation---barplots",
    "href": "3-Categorical.html#visualisation---barplots",
    "title": "ST201 Data Analysis",
    "section": "Visualisation - Barplots",
    "text": "Visualisation - Barplots\nAre these plots providing the same information?"
  },
  {
    "objectID": "3-Categorical.html#barplots",
    "href": "3-Categorical.html#barplots",
    "title": "ST201 Data Analysis",
    "section": "Barplots",
    "text": "Barplots\n\nBarplot of rating by class - stackedCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntab &lt;- table(airline)\n\nbarplot(t(tab), \n        legend = TRUE,\n        args.legend = list(x = \"top\", ncol = 2), \n        ylim = c(0,95))"
  },
  {
    "objectID": "3-Categorical.html#barplots-1",
    "href": "3-Categorical.html#barplots-1",
    "title": "ST201 Data Analysis",
    "section": "Barplots",
    "text": "Barplots\n\nBarplot of rating by classCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntab &lt;- table(airline)\n\nbarplot(t(tab), \n        beside = TRUE,\n        legend = TRUE, \n        args.legend = list(x = \"topleft\", ncol = 1),\n        ylim = c(0,40))"
  },
  {
    "objectID": "3-Categorical.html#expected-counts-in-two-way-tables",
    "href": "3-Categorical.html#expected-counts-in-two-way-tables",
    "title": "ST201 Data Analysis",
    "section": "Expected counts in two-way tables",
    "text": "Expected counts in two-way tables\n\n\n\n\n\n\nThinking about a hypothesis\n\n\nWhile we would not expect the satisfaction to be exactly the same across the classes, the rate of satistaction seems different across the two groups. In order to investigate whether the differences in satisfaction is due to natural variability in people’s honesty or due to a treatment effect (i.e., what seat that sat in), we need to compute expected (estimated) counts for each cell in a two-way table.\n\n\n\n\n\n\nOverall what proportion gave a poor satisfaction rating?\n\n\nWe see from the marginal distribution that the overall proportion of people that gave a poor satisfaction rating is 0.15 or 15%.\nIf class didn’t matter (i.e, satisfaction is independent of class), 15% of respondents would disclose this satisfaction rating regardless of their seat, so 15% in economy and 15% in business.\nBased on this line of thinking, we can compute an expected count under an independence assumption."
  },
  {
    "objectID": "3-Categorical.html#independence-and-expected-frequencies",
    "href": "3-Categorical.html#independence-and-expected-frequencies",
    "title": "ST201 Data Analysis",
    "section": "Independence and Expected Frequencies",
    "text": "Independence and Expected Frequencies\n\nTwo variables are considered to be independent if the observations on one variable do not effect the observation on another variable.\n\n\n\n\n\n\n\nExpected Frequencies\n\n\nThe expected frequencies under independence are given by\n\\[E_{\\text{row } i, \\text{col } j} = \\frac{(\\text{row i total})(\\text{column j total})}{\\text{grand total}} \\]\n\n\n\n\nFor the airline data these are\n\n\n\n\n\n\n\npoor\nfair\ngood\nv. good\n\n\n\n\nB\n4.2\n10.36\n6.44\n7\n\n\nE\n10.8\n26.64\n16.56\n18"
  },
  {
    "objectID": "3-Categorical.html#pearsons-chi2-statistic",
    "href": "3-Categorical.html#pearsons-chi2-statistic",
    "title": "ST201 Data Analysis",
    "section": "Pearson’s \\(\\chi^2\\) Statistic",
    "text": "Pearson’s \\(\\chi^2\\) Statistic\n\nPearson’s \\(\\chi^2\\) statistics is used for measuring association between variables in a contingency table.\nThe chi-squared test statistic for a two-way table is found by finding the ratio of how far the observed counts are from the expected counts, as compared to the expected counts, for every cell in the table.\n\n\n\n\n\n\n\n\\(\\chi^2\\) statistic\n\n\nThe \\(\\chi^2\\) statistic is given as:\n\\[\\chi^2 = \\sum_i \\sum_j\\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\\]"
  },
  {
    "objectID": "3-Categorical.html#chi-squared-distribution",
    "href": "3-Categorical.html#chi-squared-distribution",
    "title": "ST201 Data Analysis",
    "section": "Chi-squared distribution",
    "text": "Chi-squared distribution\nThe chi-squared test statistic has a mathematical distribution called the Chi-squared distribution.\n\n\n\nThe important specification to make in describing the chi-squared distribution is something called degrees of freedom.\nDifferent chi-squared distributions correspond to different degrees of freedom.\n\n\n\n\n\n\n\n\n\n\n\n\nFor two way tables, the degrees of freedom is equal to: \\(df\\) = (number of rows minus 1) \\(\\times\\) (number of columns minus 1).\n\nIn our airline example, the degrees of freedom parameter is: \\(df = (2-1)*(4-1) = 3\\) ."
  },
  {
    "objectID": "3-Categorical.html#chi-squared-test-of-independence",
    "href": "3-Categorical.html#chi-squared-test-of-independence",
    "title": "ST201 Data Analysis",
    "section": "Chi-squared test of independence",
    "text": "Chi-squared test of independence\nWe will use the chi-squared test statistic and the chi-squared distribution to do a hypothesis test for independence for a two-way table.\n\nthe null hypothesis is independence\nthe alternative hypothesis is no independence\n\n\n\n\n\n\n\nThe test statistic for assessing the independence between two categorical variables is a chi-squared (\\(\\chi^2\\)) test statistic\n\n\nThe statistic is a ratio of how the observed counts vary from the expected counts as compared to the expected counts.\nWhen the null hypothesis is true and some conditions are met, the test statistic has a Chi-squared distribution with \\(df = (R-1) \\times (C-1).\\)\nConditions:\n\nIndependent observations\nLarge samples: 5 expected counts in each cell"
  },
  {
    "objectID": "3-Categorical.html#chi-squared-test-of-independence-1",
    "href": "3-Categorical.html#chi-squared-test-of-independence-1",
    "title": "ST201 Data Analysis",
    "section": "Chi-squared test of independence",
    "text": "Chi-squared test of independence\nFor the airline data, if the null hypothesis is true (i.e., class has no impact on satisfaction), then the test statistic (\\(\\chi^2 = 17.99\\)) is expected to follow a Chi-squared distribution with 3 degrees of freedom.\n\nUsing this information, we can compute the p-value for the test.\n\nCode\n\n\n\n\ntab &lt;- table(airline)\nchisq.test(tab)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 17.985, df = 3, p-value = 0.0004429"
  },
  {
    "objectID": "3-Categorical.html#in-summsry",
    "href": "3-Categorical.html#in-summsry",
    "title": "ST201 Data Analysis",
    "section": "In Summsry",
    "text": "In Summsry\n\nWhen associations between variables is stronger, then the deviation between observed and expected frequencies are higher.\nA chi-squared (\\(\\chi^2\\)) test statistic summarises these deviations.\nFor the airline data \\(\\chi^2 = 17.99\\).\nIf there was independence then this value (17.99) is considered very unusual, actually we would only expect to see it less than 5% of the time.\nIn other words, for the airline data the chance of seeing a value as large as 17.99, if class and satisfaction are independent is &lt; 5%\nWe conclude (because it seems more likely) that satisfaction and airline class are independent."
  },
  {
    "objectID": "3-Categorical.html#in-summary",
    "href": "3-Categorical.html#in-summary",
    "title": "ST201 Data Analysis",
    "section": "In Summary",
    "text": "In Summary\n\nWhen associations between variables is stronger, then the deviation between observed and expected frequencies are higher.\nA chi-squared (\\(\\chi^2\\)) test statistic summarises these deviations.\nFor the airline data \\(\\chi^2 = 17.99\\).\nIf there was independence then this value (17.99) is considered very unusual, actually we would only expect to see it less than 5% of the time.\nIn other words, for the airline data the chance of seeing a value as large as 17.99, if class and satisfaction are independent is &lt; 5%\nWe conclude (because it seems more likely) that satisfaction and airline class are independent."
  },
  {
    "objectID": "3-Categorical.html",
    "href": "3-Categorical.html",
    "title": "ST201 Data Analysis",
    "section": "",
    "text": "We are often interested in the interdependence of two or more categorical variables\n\ne.g., we might be interested in whether the satisfaction of airline customers varies w.r.t the travel class (Economy, Business)\ne.g., we may want to find out of female employees at a company are paid less than male employees or vice versa. Assume in this example we have two salary categories (low, high).\n\nWhen both variables are categorical then it is possible to list all combinations of the variables and count how often the combinations occur in the data."
  },
  {
    "objectID": "4-Categorical2.html#pearsons-chi-squared-test-recap",
    "href": "4-Categorical2.html#pearsons-chi-squared-test-recap",
    "title": "ST201 Data Analysis",
    "section": "Pearson’s Chi-squared test (recap)",
    "text": "Pearson’s Chi-squared test (recap)\n\nPearson’s \\(\\chi^2\\) statistic is used for measuring association between variables in a contingency table.\n\n\n\n\n\n\n\n\\(\\chi^2\\) test of association\n\n\n\nThe \\(\\chi^2\\) statistic is given as\n\n\\[\\chi^2 = \\sum_i \\sum_j\\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\\] We use the chi-squared test statistic and the chi-squared distribution to do a hypothesis test for independence for a two-way table.\n\nDifferent chi-squared distributions correspond to different degrees of freedom.\nFor two way tables, the degrees of freedom is equal to: \\(df\\) = (number of rows minus 1) \\(\\times\\) (number of columns minus 1).\n\nConditions:\n\nIndependent observations\nLarge samples: 5 expected counts in each cell"
  },
  {
    "objectID": "4-Categorical2.html#pearsons-chi-squared-test-recap-1",
    "href": "4-Categorical2.html#pearsons-chi-squared-test-recap-1",
    "title": "ST201 Data Analysis",
    "section": "Pearson’s Chi-squared test (recap)",
    "text": "Pearson’s Chi-squared test (recap)\nState the hypothesis - the null and the alternative.\n\nH0: the variables are independent - there is no relationship between the two categorical variables. Knowing the value of one variable does not help to predict the value of the other variable.\nH1: the variables are dependent - there is a relationship between the two categorical variables. Knowing the value of one variable helps to predict the value of the other variable.\n\nChoose a significance level - common values are 0.05 (5%) or 0.01 (1%).\nGet the test statistic - We can do this in R once we have data.\nMake a decision - How does your p-value compare to the significance level?\nDraw a conclusion - Is there independence or not?"
  },
  {
    "objectID": "4-Categorical2.html#climate-example",
    "href": "4-Categorical2.html#climate-example",
    "title": "ST201 Data Analysis",
    "section": "Climate Example",
    "text": "Climate Example\nAct on climate change. The table below summarizes results from a Research poll which asked respondents their generation and whether they have personally taken action to help address climate change within the last year.\n\n\n\n\n\nGeneration\nResponse\nCount\n\n\n\n\nGen Z\nTook action\n292\n\n\nMillenial\nTook action\n885\n\n\nGen X\nTook action\n809\n\n\nBoomer & older\nTook action\n1276\n\n\nGen Z\nDidn’t take action\n620\n\n\nMillenial\nDidn’t take action\n2275\n\n\nGen X\nDidn’t take action\n2709\n\n\nBoomer & older\nDidn’t take action\n4798"
  },
  {
    "objectID": "4-Categorical2.html#chi-squared-test-in-r",
    "href": "4-Categorical2.html#chi-squared-test-in-r",
    "title": "ST201 Data Analysis",
    "section": "Chi-squared test in R",
    "text": "Chi-squared test in R\n\n\n# 1. Create a two-way contingency table\ncontingency_table &lt;- \n  xtabs(Count ~ Generation + Response, \n        data = clim_data)\n\n# 2. Do the chi-sq test\nclim_chisq_test &lt;- chisq.test(contingency_table)\n\ncontingency_table;clim_chisq_test\n\n\n                Response\nGeneration       Didn't take action Took action\n  Boomer & older               4798        1276\n  Gen X                        2709         809\n  Gen Z                         620         292\n  Millenial                    2275         885\n\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_table\nX-squared = 91.924, df = 3, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "4-Categorical2.html#mosaic-plot",
    "href": "4-Categorical2.html#mosaic-plot",
    "title": "ST201 Data Analysis",
    "section": "Mosaic Plot",
    "text": "Mosaic Plot\nA mosaic plot is a visualization technique suitable for contingency tables that resembles a standardized stacked bar plot with the benefit that we still see the relative group sizes of the primary variable as well.\n\n\nmosaic(contingency_table, \n       shade=TRUE, \n       legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPearson’s residual\n\n\n\\(r_i = \\frac{O_i - E_i}{\\sqrt{E_i}}\\)\n\n\\(r_i\\) is the Pearson residual for the i-th observation. \\(O_i\\) is the observed frequency for the i-th category. \\(E_i\\) is the expected frequency for the i-th category."
  },
  {
    "objectID": "4-Categorical2.html#reporting-on-results",
    "href": "4-Categorical2.html#reporting-on-results",
    "title": "ST201 Data Analysis",
    "section": "Reporting on results",
    "text": "Reporting on results\n\n\n\nIf I wanted to write this result up for a paper I could write:\n\n\nOf the Boomer generation, 21% indicated that they have taken action on climate change. This compares to 32% for Gen Z. A chi-square goodness of fit test was conducted to test whether taking action was independent of generation. The results were significant (\\(\\chi^2(3) = 91.92\\),\\(p &lt;&lt; 0.05\\)), suggesting that your likelihood of taking climate action is dependent on what generation you belong to.\n\n\n\n\nNotes:\n\nThe result of the statistical test is preceded by the descriptive statistics. That is, I told the reader something about what the data look like before going on to do the test.\nThe description tells you what the null hypothesis being tested is.\nA “stat block” is included given some specific information about the results of the test.\nThe results are interpreted."
  },
  {
    "objectID": "4-Categorical2.html#fishers-exact-test-independence-test-for-a-small-sample",
    "href": "4-Categorical2.html#fishers-exact-test-independence-test-for-a-small-sample",
    "title": "ST201 Data Analysis",
    "section": "Fisher’s exact test: independence test for a small sample",
    "text": "Fisher’s exact test: independence test for a small sample\nFisher’s Exact Test is used when:\n\nComparing two categorical variables in a contingency table (usually 2x2).\nSample sizes are small, where other tests like the Chi-square test might not be appropriate.\n\nFisher’s exact test is preferred when the expected values in one of the cells of the contingency table is less than 5.\n\n\nWhy use Fisher’s Exact Test?\n\nIt doesn’t rely on large sample approximations.\nIt provides an exact p-value"
  },
  {
    "objectID": "4-Categorical2.html#fishers-exact-test",
    "href": "4-Categorical2.html#fishers-exact-test",
    "title": "ST201 Data Analysis",
    "section": "Fisher’s exact test",
    "text": "Fisher’s exact test\nFishers exact test is based upon calculating directly the probability of obtaining the observed data results (or results more extreme) if the null hypothesis is actually true, using all possible 2 × 2 tables that could have been observed, for the same row and column totals as the observed data.\n\n\n\n\n\n\nFisher’s test of association\n\n\nFor a given 2x2 table, the probability of obtaining the frequencies a, b, c and d is\n\\[P(Table) = \\frac{{a+b \\choose a}{c+d \\choose c}}{{n \\choose a+c}} =  \\frac{(a+b)!(c+d)!(a+c)!(b+d)!}\n{N!a!b!c!d!}\\]\nThe p-value is the sum of the probabilities of all tables as extreme (or more extreme) than the observed one.\n\nThis tells us the probability of getting the observed table (or more extreme) if the null hypothesis is true."
  },
  {
    "objectID": "4-Categorical2.html#fishers-test",
    "href": "4-Categorical2.html#fishers-test",
    "title": "ST201 Data Analysis",
    "section": "Fisher’s test",
    "text": "Fisher’s test\nState the hypothesis - the null and the alternative.\n\nH0: the variables are independent - there is no relationship between the two categorical variables. Knowing the value of one variable does not help to predict the value of the other variable.\nH1: the variables are dependent - there is a relationship between the two categorical variables. Knowing the value of one variable helps to predict the value of the other variable.\n\nChoose a significance level - common values are 0.05 (5%) or 0.01 (1%).\nGet the test statistic - We can do this in R once we have data.\nMake a decision - How does your p-value compare to the significance level?\nDraw a conclusion - Is there independence or not?"
  },
  {
    "objectID": "4-Categorical2.html#smoking-example",
    "href": "4-Categorical2.html#smoking-example",
    "title": "ST201 Data Analysis",
    "section": "Smoking Example",
    "text": "Smoking Example\nFor our example, we want to determine whether there is a statistically significant association between smoking and being a professional athlete. Smoking can only be “yes” or “no” and being a professional athlete can only be “yes” or “no”. The two variables of interest are qualitative variables and we collected data on 14 persons.\n\n\n\n\n\n\n\n\nnon-smoker\nsmoker\n\n\n\n\nathlete\n7\n2\n\n\nnon-athlete\n2\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpected Frequencies\nRemember that the Fisher’s exact test is used when there is at least one cell in the contingency table with the expected frequencies below 5.\n\n\n\n\n\n\nnon-smoker\nsmoker\n\n\n\n\nathlete\n5.785714\n3.214286\n\n\nnon-athlete\n3.214286\n1.785714"
  },
  {
    "objectID": "4-Categorical2.html#smoking-example-in-r",
    "href": "4-Categorical2.html#smoking-example-in-r",
    "title": "ST201 Data Analysis",
    "section": "Smoking example in R",
    "text": "Smoking example in R\nFisher’s test\n\n\nsmoking_tab &lt;- table(smoking_dat)\nfisher.test(smoking_tab)\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  smoking_tab\np-value = 0.2657\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  0.2990134 99.1958282\nsample estimates:\nodds ratio \n  4.575127 \n\n\nMosaic Plot\n\n\nmosaic(smoking_tab, \n       shade=TRUE, \n       legend=FALSE)"
  },
  {
    "objectID": "4-Categorical2.html#reporting-on-results-1",
    "href": "4-Categorical2.html#reporting-on-results-1",
    "title": "ST201 Data Analysis",
    "section": "Reporting on results",
    "text": "Reporting on results\n\n\n\nIf I wanted to write this result up for a paper I could write:\n\n\nOf the 9 athletes, 2 were smokers (22%) and of the 5 Non-athletes, 3 were smokers (60%), indicating that non-athletes are almost 3 times more likely than athletes to be smokers. However, given the small sample size, Fisher’s exact test was conducted to test whether being an athlete influenced smoking habits. The results were not significant (\\(p &gt; 0.05\\)) and we concluded there is no evidence of a relationship between smoking and being an athlete based on these data.\n\n\n\n\nNotes:\n\nThe result of the statistical test is preceded by the descriptive statistics. That is, I told the reader something about what the data look like before going on to do the test.\nThe description tells you what the null hypothesis being tested is.\nA “stat block” is included given some specific information about the results of the test.\nThe results are interpreted.\n\n\n\n\n\n\n\n\n\nBeware!! The headline might read:\n\n\n“Study finds that being an Athlete reduces your chance of smoking!”"
  },
  {
    "objectID": "4-Categorical2.html#class-example",
    "href": "4-Categorical2.html#class-example",
    "title": "ST201 Data Analysis",
    "section": "Class Example",
    "text": "Class Example\n\n\n\n\n\n\nCancer\nNo cancer\nTotal\n\n\n\n\nCoffee drinkers\n3\n11\n14\n\n\nNon-coffee drinkers\n1\n15\n16\n\n\nTotal\n4\n26\n30\n\n\n\n\n\n\nPresent the null and alternative hypotheses\nCalculate the exact probability in the observed contingency table\nObtain other more extreme tables\nObtain p-values of other tables\nObtain p-value for the test\nInterpret"
  },
  {
    "objectID": "5-Categorical3.html#what-is-simpsons-paradox",
    "href": "5-Categorical3.html#what-is-simpsons-paradox",
    "title": "ST201 Data Analysis",
    "section": "What is Simpson’s Paradox?",
    "text": "What is Simpson’s Paradox?\nIgnoring an important variable can lead to Simpson’s Paradox, especially when analyzing categorical data. This paradox occurs when the relationship between two variables reverses or changes after considering a third variable.\nHow do we explore Simpsons’ paradox with categorical data?\n\nVisualisation\nProportions and Relative Risk\nOdds and Odds Ratios"
  },
  {
    "objectID": "5-Categorical3.html#example-scenario-medical-treatment-success-rates",
    "href": "5-Categorical3.html#example-scenario-medical-treatment-success-rates",
    "title": "ST201 Data Analysis",
    "section": "Example Scenario: Medical Treatment Success Rates",
    "text": "Example Scenario: Medical Treatment Success Rates\nLet’s consider two treatments, Treatment A and Treatment B, and their successes. Assume we also have information on where the treatments are carried out, either Hospital X or Hospital Y.\nData\n\n\n  Hospital Treatment Patients Successes\n1        X         A       10         5\n2        X         B       90        30\n3        Y         A       10         9\n4        Y         B       90        60\n\n\nTurning this data into contingency tables\n\n\nlibrary(vcd)\nhospital_data$Failures &lt;- \n  hospital_data$Patients -  hospital_data$Successes\n\ntreatment_tab &lt;- \n  xtabs(cbind(Successes, Failures) ~ Treatment, \n      data = hospital_data)\n\nhospital_tab &lt;- \n  xtabs(cbind(Successes, Failures)  ~ Hospital, \n      data = hospital_data)\n\ntreatment_tab;hospital_tab\n\n\n         \nTreatment Successes Failures\n        A        14        6\n        B        90       90\n\n\n        \nHospital Successes Failures\n       X        35       65\n       Y        69       31"
  },
  {
    "objectID": "5-Categorical3.html#overall-success-rates-ignoring-hospital",
    "href": "5-Categorical3.html#overall-success-rates-ignoring-hospital",
    "title": "ST201 Data Analysis",
    "section": "Overall Success Rates (ignoring hospital)",
    "text": "Overall Success Rates (ignoring hospital)\nLet’s first compare the overall success rates for both treatments, ignoring the hospital.\n\nGiven the format of this data we might deal with it a little differently in R than we’ve seen before.\n\n\n# Calculate the overall success rate for Treatment A and B\noverall_data &lt;- aggregate(cbind(Patients, Successes) ~ Treatment, \n                          data = hospital_data, sum)\noverall_data$OverallSuccessRate &lt;- \n  overall_data$Successes / overall_data$Patients\noverall_data\n\n  Treatment Patients Successes OverallSuccessRate\n1         A       20        14                0.7\n2         B      180        90                0.5\n\n\n\nWe can still visualise this, but the table is also sufficient.\n\n\n\nbarplot(overall_data$OverallSuccessRate, \n        names.arg = overall_data$Treatment,\n        main = \"Overall Success Rates by Treatment\" ,\n        ylab = \"Overall Success Rate\", \n        xlab = \"Treatment\")\n\n\n\n\n\n\n\n\n\n\nTreatment A has a higher success rate than Treatment B."
  },
  {
    "objectID": "5-Categorical3.html#success-rates-for-treatment-by-hospital",
    "href": "5-Categorical3.html#success-rates-for-treatment-by-hospital",
    "title": "ST201 Data Analysis",
    "section": "Success Rates for Treatment by Hospital",
    "text": "Success Rates for Treatment by Hospital\nNow, let’s break down the success rates based on whether treatment was performed at Hospital X or Y.\n\n# Calculate the overall success rate for Treatment A and B\nhospital_data$SuccessRate &lt;- \n  hospital_data$Successes / hospital_data$Patients\nhospital_data\n\n  Hospital Treatment Patients Successes Failures SuccessRate\n1        X         A       10         5        5   0.5000000\n2        X         B       90        30       60   0.3333333\n3        Y         A       10         9        1   0.9000000\n4        Y         B       90        60       30   0.6666667\n\n\n\nTo visualise this with a barplot we need to manipulate the data a bit:\n\n\n\nhospital_tab &lt;- xtabs(SuccessRate ~ Treatment + Hospital, \n                      data = hospital_data)\nhospital_tab\n\n\n         Hospital\nTreatment         X         Y\n        A 0.5000000 0.9000000\n        B 0.3333333 0.6666667\n\n\n\n\nbarplot(hospital_tab,\n        legend.text = TRUE,\n        beside = TRUE,\n        main = \"Success Rates by Treatment & Hospital\" ,\n        ylab = \"Success Rate\", \n        xlab = \"Hospital\")\n\n\n\n\n\n\n\n\n\n\nTreatment A has a higher success rate than Treatment B in both hospitals."
  },
  {
    "objectID": "5-Categorical3.html#example-student-admissions-at-uc-berkeley",
    "href": "5-Categorical3.html#example-student-admissions-at-uc-berkeley",
    "title": "ST201 Data Analysis",
    "section": "Example: Student Admissions at UC Berkeley",
    "text": "Example: Student Admissions at UC Berkeley\nAggregate data on applicants to graduate school at Berkeley for the six largest departments in 1973 classified by admission and sex.\nThe variables and their levels are as follows:\n\nAdmit: Admitted, Rejected\nGender: Male, Female\nDept: A, B, C, D, E, F\n\n\nadmission_dat\n\n# A tibble: 4,526 × 3\n   admit    gender dept \n   &lt;fct&gt;    &lt;fct&gt;  &lt;ord&gt;\n 1 Admitted Male   A    \n 2 Admitted Male   A    \n 3 Admitted Male   A    \n 4 Admitted Male   A    \n 5 Admitted Male   A    \n 6 Admitted Male   A    \n 7 Admitted Male   A    \n 8 Admitted Male   A    \n 9 Admitted Male   A    \n10 Admitted Male   A    \n# ℹ 4,516 more rows"
  },
  {
    "objectID": "5-Categorical3.html#odds-and-odds-ratio",
    "href": "5-Categorical3.html#odds-and-odds-ratio",
    "title": "ST201 Data Analysis",
    "section": "Odds and Odds Ratio",
    "text": "Odds and Odds Ratio\n🔍 What Are Odds?\nWhen comparing two groups (e.g., Treatment vs. Control), the odds of success for each are calculated by:\n\nCategory 1:\n\\(w1 = \\frac{\\text{Success in Group 1}}{\\text{Failure in Group 1}}\\)\nCategory 2:\n\\(w2 = \\frac{\\text{Success in Group 2}}{\\text{Failure in Group 2}}\\)\n\n🔗 What is the Odds Ratio?\nThe odds ratio tells us how much more likely success odds are in one group compared to the other:\n\\(\\text{Odds Ratio} = \\frac{w1}{w2}\\)"
  },
  {
    "objectID": "5-Categorical3.html#example-student-admissions-at-uc-berkeley-1",
    "href": "5-Categorical3.html#example-student-admissions-at-uc-berkeley-1",
    "title": "ST201 Data Analysis",
    "section": "Example: Student Admissions at UC Berkeley",
    "text": "Example: Student Admissions at UC Berkeley\nLet’s assume, upon an initial look at the data, that the tables are collapsed over department.\n\nxtabs( ~ gender + admit, data = admission_dat)\n\n        admit\ngender   Admitted Rejected\n  Female      557     1278\n  Male       1198     1493\n\n\n\nOdds\n\n\nadmission_odds &lt;- lodds(~  admit + gender, \n                        data = admission_dat, \n                        log = FALSE)\ncoef(admission_odds)\n\n\nAdmitted:Rejected|Female   Admitted:Rejected|Male \n               0.4358372                0.8024113 \n\nconfint(admission_odds)\n\n                             2.5 %    97.5 %\nAdmitted:Rejected|Female 0.3945546 0.4814394\nAdmitted:Rejected|Male   0.7436704 0.8657919\n\n\n\n\nand Odds Ratios\n\n\nadmission_OR &lt;- loddsratio(~  admit + gender, \n                           data = admission_dat, \n                           log = FALSE)\ncoef(admission_OR)\n\n\nAdmitted:Rejected/Female:Male \n                    0.5431594 \n\nconfint(admission_OR)\n\n                                  2.5 %    97.5 %\nAdmitted:Rejected/Female:Male 0.4792272 0.6156207"
  },
  {
    "objectID": "5-Categorical3.html#example-student-admissions-at-uc-berkeley-2",
    "href": "5-Categorical3.html#example-student-admissions-at-uc-berkeley-2",
    "title": "ST201 Data Analysis",
    "section": "Example: Student Admissions at UC Berkeley",
    "text": "Example: Student Admissions at UC Berkeley\nLet us look at the same data but divided into groups by department.\n\nadmission_tab &lt;- xtabs(~ gender + admit + dept, \n                       data = admission_dat)\n\naddmargins(admission_tab)\n\n, , dept = A\n\n        admit\ngender   Admitted Rejected  Sum\n  Female       89       19  108\n  Male        512      313  825\n  Sum         601      332  933\n\n, , dept = B\n\n        admit\ngender   Admitted Rejected  Sum\n  Female       17        8   25\n  Male        353      207  560\n  Sum         370      215  585\n\n, , dept = C\n\n        admit\ngender   Admitted Rejected  Sum\n  Female      202      391  593\n  Male        120      205  325\n  Sum         322      596  918\n\n, , dept = D\n\n        admit\ngender   Admitted Rejected  Sum\n  Female      131      244  375\n  Male        138      279  417\n  Sum         269      523  792\n\n, , dept = E\n\n        admit\ngender   Admitted Rejected  Sum\n  Female       94      299  393\n  Male         53      138  191\n  Sum         147      437  584\n\n, , dept = F\n\n        admit\ngender   Admitted Rejected  Sum\n  Female       24      317  341\n  Male         22      351  373\n  Sum          46      668  714\n\n, , dept = Sum\n\n        admit\ngender   Admitted Rejected  Sum\n  Female      557     1278 1835\n  Male       1198     1493 2691\n  Sum        1755     2771 4526"
  },
  {
    "objectID": "5-Categorical3.html#example-student-admissions-at-uc-berkeley-3",
    "href": "5-Categorical3.html#example-student-admissions-at-uc-berkeley-3",
    "title": "ST201 Data Analysis",
    "section": "Example: Student Admissions at UC Berkeley",
    "text": "Example: Student Admissions at UC Berkeley\nOdds\n\nadmission_odds &lt;- lodds(~  admit + gender + dept, data = admission_dat, \n                        log = FALSE)\ncoef(admission_odds)\n\nAdmitted:Rejected|Female:A   Admitted:Rejected|Male:A \n                4.68421053                 1.63578275 \nAdmitted:Rejected|Female:B   Admitted:Rejected|Male:B \n                2.12500000                 1.70531401 \nAdmitted:Rejected|Female:C   Admitted:Rejected|Male:C \n                0.51662404                 0.58536585 \nAdmitted:Rejected|Female:D   Admitted:Rejected|Male:D \n                0.53688525                 0.49462366 \nAdmitted:Rejected|Female:E   Admitted:Rejected|Male:E \n                0.31438127                 0.38405797 \nAdmitted:Rejected|Female:F   Admitted:Rejected|Male:F \n                0.07570978                 0.06267806 \n\nconfint(admission_odds)\n\n                                2.5 %     97.5 %\nAdmitted:Rejected|Female:A 2.85443740 7.68691870\nAdmitted:Rejected|Male:A   1.42119020 1.88277768\nAdmitted:Rejected|Female:B 0.91708435 4.92389276\nAdmitted:Rejected|Male:B   1.43644040 2.02451551\nAdmitted:Rejected|Female:C 0.43593215 0.61225216\nAdmitted:Rejected|Male:C   0.46729337 0.73327208\nAdmitted:Rejected|Female:D 0.43419451 0.66386323\nAdmitted:Rejected|Male:D   0.40335753 0.60654021\nAdmitted:Rejected|Female:E 0.24934640 0.39637863\nAdmitted:Rejected|Male:E   0.27979716 0.52716949\nAdmitted:Rejected|Female:F 0.04999699 0.11464631\nAdmitted:Rejected|Male:F   0.04074158 0.09642579"
  },
  {
    "objectID": "5-Categorical3.html#example-student-admissions-at-uc-berkeley-4",
    "href": "5-Categorical3.html#example-student-admissions-at-uc-berkeley-4",
    "title": "ST201 Data Analysis",
    "section": "Example: Student Admissions at UC Berkeley",
    "text": "Example: Student Admissions at UC Berkeley\nand Odds Ratios\n\nadmission_OR &lt;- loddsratio(~  admit + gender + dept, data = admission_dat, \n                        log = FALSE)\ncoef(admission_OR)\n\n        A         B         C         D         E         F \n2.8635896 1.2461048 0.8825661 1.0854419 0.8185776 1.2079151 \n\nconfint(admission_OR)\n\n      2.5 %   97.5 %\nA 1.7111703 4.792127\nB 0.5285366 2.937880\nC 0.6656152 1.170230\nD 0.8086284 1.457016\nE 0.5528574 1.212011\nF 0.6641723 2.196808"
  },
  {
    "objectID": "5-Categorical3.html#whats-going-on",
    "href": "5-Categorical3.html#whats-going-on",
    "title": "ST201 Data Analysis",
    "section": "What’s going on?",
    "text": "What’s going on?\nIn this example, Simpson’s Paradox has occurred because\n\nboth gender identity and admissions were related to a third variable, namely, the department.\nFirst, women were more likely to apply to social science departments, whereas men were more likely to apply to natural science departments.\nSecond, the acceptance rate in social science departments was less than that in natural science departments.\n\nBecause women were more likely than men to apply to programs with lower acceptance rates, when department was ignored (i.e., when the data were aggregated over dept), it seemed that women were less likely than men to be admitted to graduate school, whereas the reverse was actually true."
  },
  {
    "objectID": "5-Categorical3.html#lurking-variable",
    "href": "5-Categorical3.html#lurking-variable",
    "title": "ST201 Data Analysis",
    "section": "Lurking Variable",
    "text": "Lurking Variable\nA lurking variable is a variable that is not included as an explanatory variable in the analysis but can affect the interpretation of relationships between variables.\n\nA lurking variable can falsely identify a strong relationship between variables or it can hide the true relationship.\nTo discover lurking variables, you must take the time to understand your data and the important variables that can affect a process.\n\nIgnoring an important lurking variable can lead to Simpson’s Paradox, especially when analyzing categorical data. This paradox occurs when the relationship between two variables reverses or changes after considering a third variable."
  },
  {
    "objectID": "5-Categorical3.html#way-mosaic-plots",
    "href": "5-Categorical3.html#way-mosaic-plots",
    "title": "ST201 Data Analysis",
    "section": "2-way mosaic plots",
    "text": "2-way mosaic plots\n\n\n\n\n\n\n\n\n\n\n\n\n\nadmission_OR &lt;- loddsratio(~  admit + gender, \n                           data = admission_dat, \n                           log = FALSE)\ncoef(admission_OR)\n\nAdmitted:Rejected/Female:Male \n                    0.5431594"
  },
  {
    "objectID": "5-Categorical3.html#way-mosaic-plots-1",
    "href": "5-Categorical3.html#way-mosaic-plots-1",
    "title": "ST201 Data Analysis",
    "section": "3-way mosaic plots",
    "text": "3-way mosaic plots\n\n\n\n\n\n\n\n\n\n\n\n\n\nadmission_OR &lt;- loddsratio(~  admit + gender + dept, \n                           data = admission_dat, \n                           log = FALSE)\ncoef(admission_OR)\n\n        A         B         C         D         E         F \n2.8635896 1.2461048 0.8825661 1.0854419 0.8185776 1.2079151"
  },
  {
    "objectID": "5-Categorical3.html#example-titanic-survival-data",
    "href": "5-Categorical3.html#example-titanic-survival-data",
    "title": "ST201 Data Analysis",
    "section": "Example: Titanic Survival Data",
    "text": "Example: Titanic Survival Data\nThis data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner ‘Titanic’, summarized according to economic status (class), sex, age and survival."
  },
  {
    "objectID": "5-Categorical3.html#example-titanic-survival-data-1",
    "href": "5-Categorical3.html#example-titanic-survival-data-1",
    "title": "ST201 Data Analysis",
    "section": "Example: Titanic Survival Data",
    "text": "Example: Titanic Survival Data\n\nxtabs(Freq ~ Sex + Survived , data = titanic_df )\n\n        Survived\nSex       Yes   No\n  Male    367 1364\n  Female  344  126\n\n\n\nxtabs(Freq ~ + Sex + Survived + Class, data = titanic_df )\n\n, , Class = 1st\n\n        Survived\nSex      Yes  No\n  Male    62 118\n  Female 141   4\n\n, , Class = 2nd\n\n        Survived\nSex      Yes  No\n  Male    25 154\n  Female  93  13\n\n, , Class = 3rd\n\n        Survived\nSex      Yes  No\n  Male    88 422\n  Female  90 106\n\n, , Class = Crew\n\n        Survived\nSex      Yes  No\n  Male   192 670\n  Female  20   3"
  },
  {
    "objectID": "4-Categorical2.html",
    "href": "4-Categorical2.html",
    "title": "ST201 Data Analysis",
    "section": "",
    "text": "Pearson’s \\(\\chi^2\\) statistic is used for measuring association between variables in a contingency table.\n\n\n\n\n\n\n\n\\(\\chi^2\\) test of association\n\n\n\n\nThe \\(\\chi^2\\) statistic is given as\n\n\\[\\chi^2 = \\sum_i \\sum_j\\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\\] We use the chi-squared test statistic and the chi-squared distribution to do a hypothesis test for independence for a two-way table.\n\nDifferent chi-squared distributions correspond to different degrees of freedom.\nFor two way tables, the degrees of freedom is equal to: \\(df\\) = (number of rows minus 1) \\(\\times\\) (number of columns minus 1).\n\nConditions:\n\nIndependent observations\nLarge samples: 5 expected counts in each cell"
  },
  {
    "objectID": "5-Categorical3.html#considering-associations-with-more-than-two-categorical-variables",
    "href": "5-Categorical3.html#considering-associations-with-more-than-two-categorical-variables",
    "title": "ST201 Data Analysis",
    "section": "Considering Associations with more than two categorical variables",
    "text": "Considering Associations with more than two categorical variables\nHow do we consider associations with categorical data?\n\nVisualisation\nProportions and Relative Risk\nOdds and Odds Ratios"
  },
  {
    "objectID": "5-Categorical3.html#considering-associations-with-two-categorical-variables",
    "href": "5-Categorical3.html#considering-associations-with-two-categorical-variables",
    "title": "ST201 Data Analysis",
    "section": "Considering associations with > two categorical variables",
    "text": "Considering associations with &gt; two categorical variables\nHow do we consider associations with categorical data?\n\nVisualisation\nProportions and Relative Risk\nOdds and Odds Ratios"
  },
  {
    "objectID": "5-Categorical3.html#visualisation-2-way-mosaic-plots",
    "href": "5-Categorical3.html#visualisation-2-way-mosaic-plots",
    "title": "ST201 Data Analysis",
    "section": "Visualisation: 2-way mosaic plots",
    "text": "Visualisation: 2-way mosaic plots\n\n\n\n\n\n\n\n\n\n\n\n\n\nadmission_OR &lt;- loddsratio(~  admit + gender, \n                           data = admission_dat, \n                           log = FALSE)\ncoef(admission_OR)\n\nAdmitted:Rejected/Female:Male \n                    0.5431594"
  },
  {
    "objectID": "5-Categorical3.html#visualisation-3-way-mosaic-plots",
    "href": "5-Categorical3.html#visualisation-3-way-mosaic-plots",
    "title": "ST201 Data Analysis",
    "section": "Visualisation: 3-way mosaic plots",
    "text": "Visualisation: 3-way mosaic plots\n\n\n\n\n\n\n\n\n\n\n\n\n\nadmission_OR &lt;- loddsratio(~  admit + gender + dept, \n                           data = admission_dat, \n                           log = FALSE)\ncoef(admission_OR)\n\n        A         B         C         D         E         F \n2.8635896 1.2461048 0.8825661 1.0854419 0.8185776 1.2079151"
  },
  {
    "objectID": "Tutorial2.html",
    "href": "Tutorial2.html",
    "title": "ST201 Tutorial Sheet 2",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 4th November 2024."
  },
  {
    "objectID": "Tutorial2.html#instructions",
    "href": "Tutorial2.html#instructions",
    "title": "ST201 Tutorial Sheet 2",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 4th November 2024."
  },
  {
    "objectID": "Tutorial2.html#the-dataset",
    "href": "Tutorial2.html#the-dataset",
    "title": "ST201 Tutorial Sheet 2",
    "section": "The Dataset",
    "text": "The Dataset\nA total of 150 customers of a petrol station are asked about their satisfaction with their car or motorbike insurance. The customers were asked if their vehicle type was a petrol car, a diesel car or a motorbike and if they were satisfied or unsatisfied with their insurance cover."
  },
  {
    "objectID": "Tutorial2.html#reading-the-the-data",
    "href": "Tutorial2.html#reading-the-the-data",
    "title": "ST201 Tutorial Sheet 2",
    "section": "Reading the the Data",
    "text": "Reading the the Data\nOpen a new R script. The insurance satisfaction dataset is available on the Rstudio server in the ST201 folder in a file called insurance_dat.rds. Load the file into R and look at the data."
  },
  {
    "objectID": "Tutorial2.html#contingency-tables",
    "href": "Tutorial2.html#contingency-tables",
    "title": "ST201 Tutorial Sheet 2",
    "section": "Contingency Tables",
    "text": "Contingency Tables\nExercise 1\n\nUse the xtabs() function to create a contingency table for the insurance data called insurance_tab.\nAdd the marginal distributions to this contingency table using the function addmargins().\n\nExercise 2\nNow, suppose we are interested in looking at the table of proportions (the relative frequencies) rather than the raw frequencies as given by the contingency table above.\n\nCreate a table of proportions called insurance_prob_tab by applying the prop.table() function to the contingency table.\nUse the addmargins() function to add the marginal distributions to the proportion table created in part (a).\nWhat proportion of customers were satisfied with their insurance cover?"
  },
  {
    "objectID": "Tutorial2.html#barplots",
    "href": "Tutorial2.html#barplots",
    "title": "ST201 Tutorial Sheet 2",
    "section": "Barplots",
    "text": "Barplots\nTo visualise the data in the contingency table we can produce a stacked barplot of the data in the table using the following code:\n\nbarplot(insurance_tab,\n        legend = TRUE,\n        args.legend = list(x = \"topleft\"),# This is changing the legend position\n        ylim = c(0,110)) # This is changing the y-axis limits\n\nNote the arguments in the function:\n\nt transposes the table to put vehicle on the x-axis\nlegend = TRUE. This tells the function to add a legend to the plot\nargs.legend = list(x = \"topleft\"). This tell the function where to place the legend.\nylim = c(0,100). This tells the function to make the y-axis limits go from 0 to 100. This is useful for improving the position of the legend.\n\nExercise 3\n\nInstead of the stacked barplot, change the plot so that the bars are side by side. Change the ylim argument to improve the legend position.\nBased on the barplots, describe what you have learned about the relationship between the type of vehicle and satisfaction with insurance cover."
  },
  {
    "objectID": "Tutorial2.html#conditional-distributions",
    "href": "Tutorial2.html#conditional-distributions",
    "title": "ST201 Tutorial Sheet 2",
    "section": "Conditional Distributions",
    "text": "Conditional Distributions\nWhat proportion of people that owned diesel cars are satisfied with their insurance? To answer this we want the conditional distribution for satisfaction given diesel_car. We can get this using our contingency table as follows:\n\ninsurance_tab[1,1]/(insurance_tab[1,1] + insurance_tab[1,2])\n\nExercise 4\n\nModify the code above to find the proportion of people that owned petrol cars that were satisfied.\nWhat proportion of people that owned motorbikes were satisfied?\nBased on (b) and (c) does there appear to be a relationship between the type of vehicle and the satisfaction with insurance cover? Give a reason for your answer."
  },
  {
    "objectID": "Tutorial2.html#odds",
    "href": "Tutorial2.html#odds",
    "title": "ST201 Tutorial Sheet 2",
    "section": "Odds",
    "text": "Odds\nWe can use the following code to find the odds of being satisfied for each vehicle type on the log scale:\n\nlibrary(vcd)\nsatisfaction_odds &lt;- lodds( ~ satisfaction + vehicle, \n                            data = insurance_dat)\ncoef(satisfaction_odds)\n\nsatisfied:unsatisfied|diesel_car  satisfied:unsatisfied|motorbike \n                     -0.06669137                      -0.51082562 \nsatisfied:unsatisfied|petrol_car \n                      0.27763174 \n\n\nExercise 5\n\nModify the code to put the odds on the original scale.\nWhat are the odds of satisfaction for petrol car users? Provide an interpretation.\nWhat is the odds ratio for petrol compared to diesel car users? Provide an interpretation."
  },
  {
    "objectID": "Tutorial2.html#chi-squared-test",
    "href": "Tutorial2.html#chi-squared-test",
    "title": "ST201 Tutorial Sheet 2",
    "section": "Chi-squared test",
    "text": "Chi-squared test\nIf we want to test whether vehicle type and satisfaction are independent then we can perform Pearson’s Chi-squared test using R as follows:\n\nmy_chisq_test &lt;- chisq.test(insurance_tab)\nmy_chisq_test\n\nThe key components of the Chi-squared test are the test statistics and the p-value which are provided when you run the R code above. If you want to access specific parts of the my_chisq_test object created above then you can use the $ as follows:\n\nmy_chisq_test$statistic\n\nThis will give you the chi-squared test statistic.\nExercise 6\n\nAccess the part of my_chisq_test that provides the expected contingency table. Assuming vehicle type and satisfaction are independent, how many motorbike drivers would you expect to be unsatisfied with their insurance?\nCalculate the Pearson residual for the number of motorbike drivers that were unsatisfied with their insurance. Note that Pearson’s residuals are defined as\n\n\\[\\frac{observed - expected}{\\sqrt{expected}}.\\]\n\nWhat is the p-value for the Chi-squared test? Based on this would you conclude that vehicle type and satisfaction are independent? Give a reason for your answer."
  },
  {
    "objectID": "Tutorial2.html#mosaic-plot",
    "href": "Tutorial2.html#mosaic-plot",
    "title": "ST201 Tutorial Sheet 2",
    "section": "Mosaic Plot",
    "text": "Mosaic Plot\nYou can also use a mosaic plot to visualise the data in the contingency table as follows:\n\nlibrary(vcd)\nmosaic(~ vehicle + satisfaction ,\n       data = insurance_dat)\n\nExercise 7\n\nAdd an appropriate argument to colour the mosaic plot based on the values of the Pearson residuals.\nWhat have your learned from this plot?\n\nSAVE YOUR R SCRIPT!\nClick: file - save as"
  },
  {
    "objectID": "1-Data.html",
    "href": "1-Data.html",
    "title": "ST201 Data Analysis",
    "section": "",
    "text": "Loans DataDataset\n\n\nWe will consider a dataset with information for 50 loans\n\nEach row in the dataset represents a single loan\n\nformally, an observational unit\n\nEach column represents characteristics associated with the loan\n\nformally, a variable"
  },
  {
    "objectID": "6-DiscretePDFs.html#discrete-random-variables",
    "href": "6-DiscretePDFs.html#discrete-random-variables",
    "title": "ST201 Data Analysis",
    "section": "Discrete Random Variables",
    "text": "Discrete Random Variables\nA discrete random variable represents outcomes that take on distinct integer values, often counted or listed.\nExample: Coin Tossing Experiment\nImagine tossing a coin 3 times:\n\nPossible Outcomes: HHH, HHT, HTH, THH, HTT, THT, TTH, TTT There are 8 equally likely outcomes.\nDefine ( X ): the number of heads observed.\n\nProperties of \\(X\\)\n\nPossible Values of \\(X\\):\n\n\\(X = 0, 1, 2,\\) or \\(3\\) (number of heads from 0 to 3).\n\nInterpretation:\n\n\\(X\\) is a discrete random variable because it counts a finite set of outcomes."
  },
  {
    "objectID": "6-DiscretePDFs.html#probability-mass-function",
    "href": "6-DiscretePDFs.html#probability-mass-function",
    "title": "ST201 Data Analysis",
    "section": "Probability Mass Function",
    "text": "Probability Mass Function\nA Probability Mass Function (PMF) is a function that provides the probability that a discrete random variable is exactly equal to a particular value.\nFor a discrete random variable \\(X\\) with possible values \\(x_1, x_2, \\dots, x_n\\), the PMF, denoted as \\(P(X = x)\\) or \\(f(x)\\), assigns a probability to each possible outcome \\(x\\) such that:\n\\[P(X = x) = f(x)\\]\n\n\n\n\n\n\nProperties of a Probability Mass Function:\n\n\n\nNon-negativity: \\(f(x) \\geq 0\\) for all \\(x\\).\nNormalization: The sum of all probabilities equals 1, so \\(\\sum_x f(x) = 1\\)."
  },
  {
    "objectID": "6-DiscretePDFs.html#types-of-discrete-distributions",
    "href": "6-DiscretePDFs.html#types-of-discrete-distributions",
    "title": "ST201 Data Analysis",
    "section": "Types of Discrete Distributions",
    "text": "Types of Discrete Distributions\nWe’ll explore three important types of discrete distributions, each with unique characteristics and applications:\n\nBernoulli Distribution:\n\nDefinition: Models a single trial with two possible outcomes, typically “success” (1) or “failure” (0).\nExample: Testing for a defect in a manufactured product. Each product can either be defective (1) or non-defective (0).\nParameter: Probability of success, \\(p\\).\n\nBinomial Distribution:\n\nDefinition: Represents the number of successes in a fixed number of independent Bernoulli trials.\nExample: Counting the number of defective products in a batch of 20 items inspected on an assembly line.\nParameters: Number of trials, \\(n\\), and probability of success, \\(p\\).\n\nPoisson Distribution:\n\nDefinition: Models the number of times an event occurs within a fixed interval of time or space, given the average rate of occurrence.\nExample: Number of emails received in an hour.\nParameter: Average rate of occurrence, \\(\\lambda\\).\n\n\nThese distributions help model various types of discrete events."
  },
  {
    "objectID": "6-DiscretePDFs.html#the-bernoulli-distribution",
    "href": "6-DiscretePDFs.html#the-bernoulli-distribution",
    "title": "ST201 Data Analysis",
    "section": "The Bernoulli Distribution",
    "text": "The Bernoulli Distribution\nA ‘Bernoulli trial’ or ‘Bernoulli random variable’ is where there are just two possible outcomes which we denote either a ‘success’ or a ‘failure’.\nExample X = Defect in a manufactured product. The product can either be defective (1) or non-defective (0).\nProbability Mass Function\n\\[\\begin{eqnarray*}\nf(x)  & = & \\left\\{\\begin{array}{ll} p & \\mbox{ if $x$ = 1}\\\\\n1-p & \\mbox{ if $x$ = 0 }\\\\\n0 & \\mbox{ otherwise}  \\end{array}\\right.\n\\end{eqnarray*}\\]"
  },
  {
    "objectID": "6-DiscretePDFs.html#expected-value-and-variance",
    "href": "6-DiscretePDFs.html#expected-value-and-variance",
    "title": "ST201 Data Analysis",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\nDefinition: The expected value of a discrete random variable is defined as\n\\[E[X] = \\sum_xxP(X=x) \\] Definition: The variance of a discrete random variable is defined as\n\\[Var[X] = E[X^2] - E[X]^2\\]"
  },
  {
    "objectID": "6-DiscretePDFs.html#the-binomial-distribution",
    "href": "6-DiscretePDFs.html#the-binomial-distribution",
    "title": "ST201 Data Analysis",
    "section": "The Binomial Distribution",
    "text": "The Binomial Distribution\nIf \\(n\\) Bernoulli trials all with probability \\(p\\) are performed independently, then \\(X\\), the number of successes out of the \\(n\\) trials is said to be a binomial random variable with parameters \\(n\\) and \\(p\\).\nExample 200 patients take a drug that has success probability 0.75. Let \\(X\\) = # successes. We write: \\[X \\sim Binomial(n=200, p=0.75).\\]\nProbability mass function\nIf \\(X \\sim\\) Binomial(\\(n,p\\)), the possible outcomes are k = 0, 1, 2, …, \\(n\\).\n\\[P(X=k) = {n \\choose k}p^k(1-p)^{n-k}\\]\nExpected value\nE[\\(X\\)] = \\(np\\)\nVariance\nVar(\\(X\\)) = \\(np(1-p)\\)"
  },
  {
    "objectID": "6-DiscretePDFs.html#assumptions-for-a-binomial-random-variable",
    "href": "6-DiscretePDFs.html#assumptions-for-a-binomial-random-variable",
    "title": "ST201 Data Analysis",
    "section": "Assumptions for a Binomial Random Variable",
    "text": "Assumptions for a Binomial Random Variable\nFor a random variable to follow a Binomial distribution, these key assumptions must hold:\n\nTwo Possible Outcomes per Trial\nEach trial has only two possible outcomes, typically labeled as “success” or “failure”.\nIndependence of Trials\nThe outcome of one trial does not influence the outcome of another; trials are independent.\nConstant Probability of Success (p) The probability of success remains the same for each trial.\nFixed Number of Trials (n) The process consists of a pre-determined, fixed number of identical trials."
  },
  {
    "objectID": "6-DiscretePDFs.html#binomial-example",
    "href": "6-DiscretePDFs.html#binomial-example",
    "title": "ST201 Data Analysis",
    "section": "Binomial Example",
    "text": "Binomial Example\nHospital records show that of patients suffering from a certain disease, 10% die of it. Assume we monitor 50 randomly selected patients with the disease. What is the probability mass function?\n\n\nn &lt;- 50\np &lt;- 0.9\nk &lt;- 0:n\npmf &lt;- dbinom(k,n,p)\nround(pmf,2)\n\n\n [1] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[16] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[31] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.02 0.03 0.06 0.11 0.15\n[46] 0.18 0.18 0.14 0.08 0.03 0.01\n\n\n\n\nplot(k,pmf, type = \"h\")"
  },
  {
    "objectID": "6-DiscretePDFs.html#cumulative-distribution-function-cdf",
    "href": "6-DiscretePDFs.html#cumulative-distribution-function-cdf",
    "title": "ST201 Data Analysis",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\n\n\n\n\n\n\nCumulative Distribution Function (CDF)\n\n\nThe Cumulative Distribution Function (CDF) gives the probability that the variable takes on a value less than or equal to a specified value.\n\n\n\nDefinition\nThe CDF of a binomial random variable \\(X\\), denoted as \\(F(x)\\), is given by:\n\\[\nF(x) = P(X \\leq x) = \\sum_{k=0}^{\\lfloor x \\rfloor} P(X = k) = \\sum_{k=0}^{\\lfloor x \\rfloor} \\binom{n}{k} p^k (1 - p)^{n - k}\n\\]\n\n\n\n\n\n\n\nKey Points\n\nThe CDF is a non-decreasing function that ranges from 0 to 1.\nAs \\(x\\) increases, \\(F(x)\\) approaches 1.\nThe CDF can be used to calculate probabilities for a range of outcomes and is useful in hypothesis testing and statistical inference."
  },
  {
    "objectID": "6-DiscretePDFs.html#binomial-example-1",
    "href": "6-DiscretePDFs.html#binomial-example-1",
    "title": "ST201 Data Analysis",
    "section": "Binomial Example",
    "text": "Binomial Example\nHospital records show that of patients suffering from a certain disease, 10% die of it. Assume we monitor 50 randomly selected patients with the disease. What is the cumulative distribution function?\n\n\nn &lt;- 50\np &lt;- 0.9\nk &lt;- 0:n\ncdf &lt;- pbinom(k,n,p)\nround(cdf,2)\n\n\n [1] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[16] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[31] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.02 0.06 0.12 0.23 0.38\n[46] 0.57 0.75 0.89 0.97 0.99 1.00\n\n\n\n\nplot(k,cdf)"
  },
  {
    "objectID": "6-DiscretePDFs.html#binomial-example-2",
    "href": "6-DiscretePDFs.html#binomial-example-2",
    "title": "ST201 Data Analysis",
    "section": "Binomial Example",
    "text": "Binomial Example\nWhat is the probability that of 50 randomly selected patients, exactly 40 will recover?\n\ndbinom(x = 40, size = 50, prob = 0.9)\n\n[1] 0.01518333\n\n\nWhat is the probability that of 50 randomly selected patients, 45 or more will recover?\n\n1 - pbinom(q = 44,size = 50, prob = 0.9)\n\n[1] 0.616123\n\n\nWhat is the 80th percentile of this distribution?\n\nqbinom(p = 0.8,size = 50, prob = 0.9)\n\n[1] 47"
  },
  {
    "objectID": "6-DiscretePDFs.html#the-poisson-distribution",
    "href": "6-DiscretePDFs.html#the-poisson-distribution",
    "title": "ST201 Data Analysis",
    "section": "The Poisson Distribution",
    "text": "The Poisson Distribution\nThe Poisson distribution is a probability model for count data. You can use a Poisson distribution to predict or explain the number of events occurring within a given interval of time or space\nPoisson Example\nSuppose the average number road deaths per month is estimated to be 12. The we say X, the number of road deaths per months has a Poisson distribution with rate \\(\\lambda = 12\\).\n\\[X \\sim Poisson(\\lambda = 12).\\]\nProbability Mass Function\n\\[P(X=k) = \\frac{e^{-\\lambda}\\lambda^k}{k!}, \\hspace{1em} k = 1,2, \\ldots\\]\nExpected value and variance\n\n\\(E[X] = \\lambda\\), \\(Var(X) = \\lambda\\)"
  },
  {
    "objectID": "6-DiscretePDFs.html#example",
    "href": "6-DiscretePDFs.html#example",
    "title": "ST201 Data Analysis",
    "section": "Example",
    "text": "Example\nSuppose a country experiences 4 tropical storms on average per year. What is the probability mass function?\n\n\nn &lt;- 40\nlambda &lt;- 4\nk &lt;- 0:n\npmf &lt;- dpois(k,lambda)\nround(pmf,2)\n\n\n [1] 0.02 0.07 0.15 0.20 0.20 0.16 0.10 0.06 0.03 0.01 0.01 0.00 0.00 0.00 0.00\n[16] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[31] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n\n\n\n\nplot(k,pmf, type = \"h\")"
  },
  {
    "objectID": "6-DiscretePDFs.html#cumulative-distribution-function-cdf-2",
    "href": "6-DiscretePDFs.html#cumulative-distribution-function-cdf-2",
    "title": "ST201 Data Analysis",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\nDefinition\nFor a Poisson random variable \\(X\\) that represents the number of events occurring in a fixed interval of time or space, given an average rate of occurrence \\(\\lambda\\), the CDF is defined as follows:\n\\[\nF(x) = P(X \\leq x) = \\sum_{k=0}^{\\lfloor x \\rfloor} P(X = k) = \\sum_{k=0}^{\\lfloor x \\rfloor} \\frac{e^{-\\lambda} \\lambda^k}{k!}\n\\]\nKey Points\n\nThe CDF is a non-decreasing function ranging from 0 to 1.\nAs \\(x\\) increases, \\(F(x)\\) approaches 1.\nThe CDF can be used to determine probabilities for various outcomes and is useful in statistical analysis, such as hypothesis testing and confidence intervals for count data."
  },
  {
    "objectID": "6-DiscretePDFs.html#poisson-example",
    "href": "6-DiscretePDFs.html#poisson-example",
    "title": "ST201 Data Analysis",
    "section": "Poisson Example",
    "text": "Poisson Example\nSuppose a country experiences 4 tropical storms on average per year. What is the probability mass function?\n\n\nn &lt;- 40\nlambda &lt;- 4\nk &lt;- 0:n\npmf &lt;- dpois(k,lambda)\nround(pmf,2)\n\n\n [1] 0.02 0.07 0.15 0.20 0.20 0.16 0.10 0.06 0.03 0.01 0.01 0.00 0.00 0.00 0.00\n[16] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[31] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n\n\n\n\nplot(k,pmf, type = \"h\")"
  },
  {
    "objectID": "6-DiscretePDFs.html#poisson-example-1",
    "href": "6-DiscretePDFs.html#poisson-example-1",
    "title": "ST201 Data Analysis",
    "section": "Poisson Example",
    "text": "Poisson Example\nSuppose a country experiences 4 tropical storms on average per year. What is the cumulative distribution function?\n\n\nn &lt;- 40\nlambda &lt;- 4\nk &lt;- 0:n\ncdf &lt;- ppois(k, lambda)\nround(cdf,2)\n\n\n [1] 0.02 0.09 0.24 0.43 0.63 0.79 0.89 0.95 0.98 0.99 1.00 1.00 1.00 1.00 1.00\n[16] 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n[31] 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\n\n\n\n\nplot(k,cdf)"
  },
  {
    "objectID": "6-DiscretePDFs.html#expected-value-and-variance-1",
    "href": "6-DiscretePDFs.html#expected-value-and-variance-1",
    "title": "ST201 Data Analysis",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\nDefinition: The expected value of a discrete random variable is defined as\n\\[E[X] = \\sum_xxP(X=x) \\] Definition: The variance of a discrete random variable is defined as\n\\[Var[X] = E[X^2] - E[X]^2\\]\nExpected value for a Bernoulli Random Variable\n\nE[\\(X\\)] = \\((0 \\times P[X=0]) + (1 \\times P[X=1]) = p\\)\n\nVariance for a Bernoulli Random Variable\n\nE[\\(X^2\\)] = \\((0^2 \\times p(0)) + (1^2 \\times p(1)) = p\\)\nVar(\\(X\\)) = E[\\(X^2\\)] - \\((E[X])^2 = p - p^2 = p(1-p)\\)"
  },
  {
    "objectID": "6-DiscretePDFs.html#poisson-example-2",
    "href": "6-DiscretePDFs.html#poisson-example-2",
    "title": "ST201 Data Analysis",
    "section": "Poisson Example",
    "text": "Poisson Example\nWhat is the probability the country experiences 6 tropical storms in a given year.\n\ndpois(x = 6,lambda)\n\n[1] 0.1041956\n\n\nWhat is the probability more than 4 storms will occur?\n\n1 - ppois(q = 4,lambda)\n\n[1] 0.3711631\n\n\nWhat is the 80th percentile of this distribution?\n\nqpois(p = 0.8,lambda)\n\n[1] 6"
  },
  {
    "objectID": "Tutorial3.html",
    "href": "Tutorial3.html",
    "title": "ST201 Tutorial Sheet 3",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 18th November 2024.\n\nExercise 1\nA multiple choice exam has 8 questions, with four choices given in each question. Suppose that a student hasn’t studied and guesses the answers by choosing an answer at random.\nIf we say that X is the number of times the student answers the question correctly, where\n\\(X \\sim Binomial(n = 8, p = 0.25)\\)\nthen we can find probabilities and quantiles using the dbinom(), pbinom() and qbinom() functions.\n\nNote: To think about why we choose these values for \\(n\\) and \\(p\\) in the binomial distribution we need to consider the following:\n\nIn terms of answers to the questions, they can either be right or wrong, so for each question we have a binary outcome.\nThe number of “trials” you have is 8 (i.e., 8 questions)\nThe probability of getting a question correct by chance is 1/4 (i.e., for each question there are 4 possible answers with 1 being the correct answer)\n\n\n\nCompute the probability that the student answers all questions correctly?\nCompute the probability that the student answers all questions incorrectly.\nCompute the probability that the student answers 2 or more correctly.\nWhat is the 60th percentile for this distribution?\nSuppose the student is able to eliminate one of the answers as incorrect and chooses randomly from the other three choices. What is the probability the student answers 2 or more questions correctly?\n\nExercise 2\nAssume that users are expected to arrive at an ATM to withdraw cash at a rate of 2.5 every 30 minutes.\nIf we say that the random variable X, the number of people that use the ATM in a 30 minute interval has a Poisson distribution such that\n\\[X \\sim Poisson(\\lambda = 2.5)\\]\nWe can find probabilities and quantiles using the dpois(), ppois() and qpois() functions.\n\nNote: To think about how we choose \\(\\lambda\\) in the Poisson distribution we need to consider the following:\n\nWhat is the interval we are assuming when calculating the probability?\n\nIf we are interested in a 30 minute interval the we use \\(\\lambda = 2.5\\)\nIf we change the interval then we change \\(\\lambda\\), for example, if we are interested in a 15 minute interval the we use \\(\\lambda = 1.25\\).\n\n\n\n\nCompute the probability that in a particular 30 minute interval, 1 person uses the machine.\nCompute the probability that in a particular 30 minute interval, more than one person uses the machine.\nCompute the probability that 3 or more people use the machine in an hour interval.\nWhat is the 90th percentile value for the number of machine users in an hour interval?\n\nExercise 3\nA fisherman catches, on average, 24 fish in a 4 hour time period. Let Y be a random variable denoting the number of fish caught per hour hour.\n\nWhat is the E(Y)?\nWhat is the probability that the fisherman catches exactly 5 fish in an hour?\nWhat is the probability that the fisherman catches 7 or more fish in a 2 hour period?\n\nExercise 4\nAssume that 20% of the emails that a University lecturer receives come from students. Let X be a random variable denoting the number of non-student emails.\n\nIf the lecturer receives a total of 50 emails on a given day. What is the expected number of non-student emails that the lecturer receives.\nWhat is the probability exactly 10 of the emails are from students?\nWhat is the probability the lecturer receives more than 40 non-student emails.\nSimulate 100 samples from the Binomial distribution specified above. What is the mean of the samples, how does that compare to (a). Work out the probability from (c) using the simulated samples. Repeat but by simulating 10000 samples. Does this change the results?"
  },
  {
    "objectID": "Tutorial3.html#instructions",
    "href": "Tutorial3.html#instructions",
    "title": "ST201 Tutorial Sheet 3",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 18th November 2024.\n\nExercise 1\nA multiple choice exam has 8 questions, with four choices given in each question. Suppose that a student hasn’t studied and guesses the answers by choosing an answer at random.\nIf we say that X is the number of times the student answers the question correctly, where\n\\(X \\sim Binomial(n = 8, p = 0.25)\\)\nthen we can find probabilities and quantiles using the dbinom(), pbinom() and qbinom() functions.\n\nNote: To think about why we choose these values for \\(n\\) and \\(p\\) in the binomial distribution we need to consider the following:\n\nIn terms of answers to the questions, they can either be right or wrong, so for each question we have a binary outcome.\nThe number of “trials” you have is 8 (i.e., 8 questions)\nThe probability of getting a question correct by chance is 1/4 (i.e., for each question there are 4 possible answers with 1 being the correct answer)\n\n\n\nCompute the probability that the student answers all questions correctly?\nCompute the probability that the student answers all questions incorrectly.\nCompute the probability that the student answers 2 or more correctly.\nWhat is the 60th percentile for this distribution?\nSuppose the student is able to eliminate one of the answers as incorrect and chooses randomly from the other three choices. What is the probability the student answers 2 or more questions correctly?\n\nExercise 2\nAssume that users are expected to arrive at an ATM to withdraw cash at a rate of 2.5 every 30 minutes.\nIf we say that the random variable X, the number of people that use the ATM in a 30 minute interval has a Poisson distribution such that\n\\[X \\sim Poisson(\\lambda = 2.5)\\]\nWe can find probabilities and quantiles using the dpois(), ppois() and qpois() functions.\n\nNote: To think about how we choose \\(\\lambda\\) in the Poisson distribution we need to consider the following:\n\nWhat is the interval we are assuming when calculating the probability?\n\nIf we are interested in a 30 minute interval the we use \\(\\lambda = 2.5\\)\nIf we change the interval then we change \\(\\lambda\\), for example, if we are interested in a 15 minute interval the we use \\(\\lambda = 1.25\\).\n\n\n\n\nCompute the probability that in a particular 30 minute interval, 1 person uses the machine.\nCompute the probability that in a particular 30 minute interval, more than one person uses the machine.\nCompute the probability that 3 or more people use the machine in an hour interval.\nWhat is the 90th percentile value for the number of machine users in an hour interval?\n\nExercise 3\nA fisherman catches, on average, 24 fish in a 4 hour time period. Let Y be a random variable denoting the number of fish caught per hour hour.\n\nWhat is the E(Y)?\nWhat is the probability that the fisherman catches exactly 5 fish in an hour?\nWhat is the probability that the fisherman catches 7 or more fish in a 2 hour period?\n\nExercise 4\nAssume that 20% of the emails that a University lecturer receives come from students. Let X be a random variable denoting the number of non-student emails.\n\nIf the lecturer receives a total of 50 emails on a given day. What is the expected number of non-student emails that the lecturer receives.\nWhat is the probability exactly 10 of the emails are from students?\nWhat is the probability the lecturer receives more than 40 non-student emails.\nSimulate 100 samples from the Binomial distribution specified above. What is the mean of the samples, how does that compare to (a). Work out the probability from (c) using the simulated samples. Repeat but by simulating 10000 samples. Does this change the results?"
  },
  {
    "objectID": "8-ContinuousPDFs.html#continuous-random-variables",
    "href": "8-ContinuousPDFs.html#continuous-random-variables",
    "title": "ST201 Data Analysis",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\nA continuous random variable is a variable that can take any real value within an interval, meaning it can assume an infinite number of possible values across the specified range. Common intervals include:\n\nWhole real line: \\((- \\infty, \\infty)\\)\nPositive real line: \\((0, \\infty)\\)\nFinite intervals: \\((5, 25)\\), \\((a, b)\\), etc.\n\nKey Characteristics\n\nValues are not countable—there’s an infinite number of possible outcomes.\nTypically modeled with a probability density function (PDF).\n\nExamples:\n\nAmount of rainfall in a day (measured in mm)\nDistance covered in a training session (km)\nWeight of a book (grams)"
  },
  {
    "objectID": "8-ContinuousPDFs.html#properties-of-continuous-probability-distributions",
    "href": "8-ContinuousPDFs.html#properties-of-continuous-probability-distributions",
    "title": "ST201 Data Analysis",
    "section": "Properties of Continuous Probability Distributions",
    "text": "Properties of Continuous Probability Distributions\n\nThe outcomes are measured, not counted.\nThe graph of a continuous probability distribution is a curve. Probability is represented by area under the curve.\nThe curve is called the probability density function (abbreviated as pdf). We use the symbol f(x) to represent the curve.\nArea under the curve is given by a function called the cumulative distribution function (abbreviated as cdf). The cumulative distribution function, F(x), is used to evaluate probability as area.\nIn technical terms\n\n\\[F(x) = P(X \\le x) = \\displaystyle\\int_{-\\infty}^{x} f(u) du\\].\nThe expected value of a continuous random variable is defined as\n\\[E[X] = \\int_{-\\infty}^{-\\infty}xf(x) dx\\]\nThe variance of a discrete random variable is defined as\n\\[Var[X] = E[X^2] - E[X]^2\\]"
  },
  {
    "objectID": "8-ContinuousPDFs.html#properties-of-continuous-probability-distributions-1",
    "href": "8-ContinuousPDFs.html#properties-of-continuous-probability-distributions-1",
    "title": "ST201 Data Analysis",
    "section": "Properties of Continuous Probability Distributions",
    "text": "Properties of Continuous Probability Distributions\n\nThe entire area under the curve and above the x-axis is equal to one. In technical terms\n\n\\[\\displaystyle\\int_{-\\infty}^{\\infty} f(x) dx = 1\\].\n\nProbability is found for intervals of x values rather than for individual x values.\n\\(P(c &lt; x &lt; d)\\) is the probability that the random variable X is in the interval between the values c and d. This equates to the area under the curve, above the x-axis, to the right of c and the left of d.\n\\(P(x = c) = 0\\). The probability that x takes on any single individual value is zero."
  },
  {
    "objectID": "8-ContinuousPDFs.html#types-of-continuous-distributions",
    "href": "8-ContinuousPDFs.html#types-of-continuous-distributions",
    "title": "ST201 Data Analysis",
    "section": "Types of continuous distributions",
    "text": "Types of continuous distributions\nWe will look at 3 types of continuous distributions. These are the:\n\nUniform distribution\nExponential distribution\nNormal distribution\n\nFor continuous probability distributions, PROBABILITY = AREA."
  },
  {
    "objectID": "8-ContinuousPDFs.html#the-uniform-distribution",
    "href": "8-ContinuousPDFs.html#the-uniform-distribution",
    "title": "ST201 Data Analysis",
    "section": "The Uniform Distribution",
    "text": "The Uniform Distribution\nSuppose I choose a number randomly from [a,b].\n\nLet \\(X\\) be the resulting number, then \\(X \\sim\\) Uniform [a,b]\n\nPDF and CDF\n\\[\\begin{eqnarray*}\nf(x)  & = & \\left\\{\\begin{array}{ll}\n0 & \\mbox{ if $x &lt; a$}\\\\\n\\frac{1}{b-a} & \\mbox{ if $a \\le x \\le b$}\\\\\n0 & \\mbox{ if $x &gt; b$}  \n\\end{array}\\right.\n\\end{eqnarray*}\\]\n\\[\\begin{eqnarray*}\nF(x) = P(X \\leq x)   & = & \\left\\{\\begin{array}{ll}\n0 & \\mbox{ if $x &lt; a$}\\\\\n\\frac{x-a}{b-a} & \\mbox{ if $a \\le x \\le b$}\\\\\n1 & \\mbox{ if $x &gt; b$}  \n\\end{array}\\right.\n\\end{eqnarray*}\\]\nE[X] and Var[X] for a uniform random variable:\n\n\\(E(X) = \\mu = \\frac{a+b}{2}\\)\n\\(Var(X) = \\sigma^2 = \\frac{(b-a)^2}{12}\\)"
  },
  {
    "objectID": "8-ContinuousPDFs.html#expected-value-and-variance",
    "href": "8-ContinuousPDFs.html#expected-value-and-variance",
    "title": "ST201 Data Analysis",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\nDefinition: The expected value of a continuous random variable is defined as\n\\[E[X] = \\int_a^bxf(x) \\]\nDefinition: The variance of a discrete random variable is defined as\n\\[Var[X] = E[X^2] - E[X]^2\\]"
  },
  {
    "objectID": "8-ContinuousPDFs.html#example",
    "href": "8-ContinuousPDFs.html#example",
    "title": "ST201 Data Analysis",
    "section": "Example",
    "text": "Example\nThe net weight of a packages has a uniform distribution over the interval 980 g to 1030 g.\n\nWhat is the expected weight of a package?\nWhat is the probability that a package weighs less than 1000 g?\nWhat is the probability that a package weighs between 990 and 1010 g?\nWhat is the 75th percentile of this distribution?\n\n\npunif(1000, 980, 1030)\n\n[1] 0.4\n\npunif(1010, 980, 1030) - punif(990, 980, 1030)\n\n[1] 0.4\n\nqunif(0.75, 980, 1030)\n\n[1] 1017.5"
  },
  {
    "objectID": "8-ContinuousPDFs.html#the-exponential-distribution",
    "href": "8-ContinuousPDFs.html#the-exponential-distribution",
    "title": "ST201 Data Analysis",
    "section": "The Exponential Distribution",
    "text": "The Exponential Distribution\nThe exponential distribution is often concerned with the amount of time until some specific event occurs.\nExample\nLet \\(X\\) = time between events. On average there are \\(\\lambda\\) events per unit of time.\nWe can model this as \\(X \\sim\\) exponential(\\(\\lambda\\)).\nPDF and CDF\n\\[f(x) = \\lambda e^{-\\lambda x} \\mbox{ with }x \\ge 0\\]\n\\[\\begin{eqnarray*}\nF(x) &=& P(X \\le x) = \\int_{0}^{x}\\lambda e^{-\\lambda u} du\\\\\n&=& 1 - e^{-\\lambda x}\n\\end{eqnarray*}\\]\nE[X] and Var[X] for an exponential random variable:\n\\(E[X] = \\frac{1}{\\lambda}\\) \\(Var(X) = \\frac{1}{\\lambda^2}\\)"
  },
  {
    "objectID": "8-ContinuousPDFs.html#example-1",
    "href": "8-ContinuousPDFs.html#example-1",
    "title": "ST201 Data Analysis",
    "section": "Example",
    "text": "Example\nLet Y be the random variable which counts the “number of accesses per second for a search engine”. Assume that Y is Poisson distributed with parameter \\(\\lambda = 10\\) (E[Y] = 10, Var[Y] = 10). The random variable X, “waiting time until the next access”, is then exponentially distributed with parameter \\(\\lambda = 10\\)\n\nWhat is the expected waiting time for next access?\nWhat is the probability that the waiting time is \\(\\le\\) 0.6 seconds?\nWhat is the probability that the waiting time is in [0.05, 0.2] seconds?\nWhat is the 80th percentile of this distribution?\n\n\npexp(0.6, rate = 10)\n\n[1] 0.9975212\n\npexp(0.2, rate = 10) - pexp(0.05, rate = 10)\n\n[1] 0.4711954\n\nqexp(0.8, 10)\n\n[1] 0.1609438"
  },
  {
    "objectID": "8-ContinuousPDFs.html#the-normal-distribution",
    "href": "8-ContinuousPDFs.html#the-normal-distribution",
    "title": "ST201 Data Analysis",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\nThis continuous distribution is one of the most commonly used distributions in statistics. It is used to model, for example,\n\nexperimental errors in scientific measurements\ntest scores in aptitude tests\nheights of people selected at random from a population.\n\nThe normal distribution has two parameters (two numerical descriptive measures), the mean (\\(\\mu\\)) and the standard deviation (\\(\\sigma\\)). If X is a quantity to be measured that has a normal distribution with mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)), we designate this by writing\n\\[X \\sim N(\\mu, \\sigma)\\]"
  },
  {
    "objectID": "8-ContinuousPDFs.html#the-normal-distribution-1",
    "href": "8-ContinuousPDFs.html#the-normal-distribution-1",
    "title": "ST201 Data Analysis",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\nPDF\nThis is a rather complicated function.\n\\[f(x) = \\frac{1}{ \\sqrt{2\\pi\\sigma^2} }e^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}}\\] with \\(-\\infty &lt; x &lt; \\infty\\).\nE[X] and Var[X] for a normal random variable:\n\nE[\\(X\\)] = \\(\\mu\\)\nVar(\\(X\\)) = \\(\\sigma^2\\)"
  },
  {
    "objectID": "8-ContinuousPDFs.html#properties-of-the-normal-distribution",
    "href": "8-ContinuousPDFs.html#properties-of-the-normal-distribution",
    "title": "ST201 Data Analysis",
    "section": "Properties of the normal distribution",
    "text": "Properties of the normal distribution\n\nThe shape of the normal pdf is described as bell shaped. It is symmetric about \\(\\mu\\) (half of the area under the curve is above and half below \\(\\mu\\)).\nApproximately 68% of the area under the curves lies in (\\(\\mu-\\sigma\\), \\(\\mu+\\sigma\\)).\nApproximately 95% of the area under the curves lies in (\\(\\mu-2\\sigma\\), \\(\\mu+2\\sigma\\)).\nApproximately 99.7% of the area under the curves lies in (\\(\\mu-3\\sigma\\), \\(\\mu+3\\sigma\\)).\nThis is known as the 68-95-99.7 rule. Graphically it is represented by:"
  },
  {
    "objectID": "8-ContinuousPDFs.html#example-2",
    "href": "8-ContinuousPDFs.html#example-2",
    "title": "ST201 Data Analysis",
    "section": "Example",
    "text": "Example\nAn orange farmer sells his oranges in wooden boxes. The weights of the boxes vary and are assumed to be normally distributed with \\(\\mu = 15\\) kg and \\(\\sigma^2 =2.25\\) kg\\(^2\\).\n\nWhat is the probability that a box with a weight of less than 13 kg is sold?\nWhat is the probability that the weight is between 12 and 14 kg?\nWhat is the 68th percentile of this distribution?\n\n\npnorm(13, 15, sqrt(2.25))\n\n[1] 0.09121122\n\npnorm(14, 15, sqrt(2.25)) - pnorm(12, 15, sqrt(2.25))\n\n[1] 0.2297424\n\nqnorm(0.68, 15, sqrt(2.25))\n\n[1] 15.70155"
  },
  {
    "objectID": "Tutorial4.html",
    "href": "Tutorial4.html",
    "title": "ST201 Tutorial Sheet 4",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 2nd December 2024.\n\nExercise 1\nSuppose the average time between checkouts for a supermarket cashier is three minutes. Let X be a random variable describing the the time between checkouts and assume X follows an exponential distribution.\n\n\n\n\n\n\n\nWhat is the value of the parameter \\(\\lambda\\) in the exponential distribution?\nUse rexp() to simulate 10,000 values from this distribution and plot the density curve.\nCalculate the probability of the time between checkouts being \\(\\leq\\) 2 minutes.\nWhat is the 80th percentile for this distribution?\n\n\nExercise 2\nSuppose a Normal Distribution has \\(\\mu\\) = 0 and \\(\\sigma = 1\\).\n\nUse rnorm() to simulate 10,000 values from this distribution and plot the density curve.\nUsing the pnorm() function, calculate the area below -1, above 2, between -1 and 2.\nPlot the cumulative probability distribution function for the sequence of values between -4 and 4 at intervals of 0.1.\nUsing qnorm(), what is the median of the distribution? The upper and lower quartiles? Find the 2.5th and 97.5th percentile values.\nHow do your answers in (d) compare to answers you get when you apply the quantile() function to your simulated values from (a)?\n\n\nExercise 3\n\nIQ tests are designed so that the average IQ is 100, the standard deviation of IQ scores is 15, and the distribution of IQ scores is normal. Run an experiment. Sample N = 5 people’s IQ scores (using the population characteristics). Check the mean IQ for your sample.\nNow replicate the experiment. That is, randomly sample 5 new people and measure their IQ. Check the mean IQ for your sample.\nRepeat the experiment 1000 times and store the means in an object called IQ_means (note we’ll see a similar example in Week9)\nPlot the distributions of sample means using a histogram. Overlay a density plot that reflects the population distribution. How does the distribution of the sample means compare to the population distribution for IQ scores?\nIf you sampled N = 100 IQ scores instead of N = 5, how would this impact the sampling distributions?\n\n\nExercise 4\nSuppose we get 40 students from Maynooth campus to sit through an IQ test. The test results can be found in IQ_dat.rda in the ST201 folder on the R studio server. Based on this sample, what is the 95% confidence interval for the population mean IQ?"
  },
  {
    "objectID": "Tutorial4.html#instructions",
    "href": "Tutorial4.html#instructions",
    "title": "ST201 Tutorial Sheet 4",
    "section": "",
    "text": "Attempt the questions below before your tutorial in the week beginning 2nd December 2024.\n\nExercise 1\nSuppose the average time between checkouts for a supermarket cashier is three minutes. Let X be a random variable describing the the time between checkouts and assume X follows an exponential distribution.\n\n\n\n\n\n\n\nWhat is the value of the parameter \\(\\lambda\\) in the exponential distribution?\nUse rexp() to simulate 10,000 values from this distribution and plot the density curve.\nCalculate the probability of the time between checkouts being \\(\\leq\\) 2 minutes.\nWhat is the 80th percentile for this distribution?\n\n\nExercise 2\nSuppose a Normal Distribution has \\(\\mu\\) = 0 and \\(\\sigma = 1\\).\n\nUse rnorm() to simulate 10,000 values from this distribution and plot the density curve.\nUsing the pnorm() function, calculate the area below -1, above 2, between -1 and 2.\nPlot the cumulative probability distribution function for the sequence of values between -4 and 4 at intervals of 0.1.\nUsing qnorm(), what is the median of the distribution? The upper and lower quartiles? Find the 2.5th and 97.5th percentile values.\nHow do your answers in (d) compare to answers you get when you apply the quantile() function to your simulated values from (a)?\n\n\nExercise 3\n\nIQ tests are designed so that the average IQ is 100, the standard deviation of IQ scores is 15, and the distribution of IQ scores is normal. Run an experiment. Sample N = 5 people’s IQ scores (using the population characteristics). Check the mean IQ for your sample.\nNow replicate the experiment. That is, randomly sample 5 new people and measure their IQ. Check the mean IQ for your sample.\nRepeat the experiment 1000 times and store the means in an object called IQ_means (note we’ll see a similar example in Week9)\nPlot the distributions of sample means using a histogram. Overlay a density plot that reflects the population distribution. How does the distribution of the sample means compare to the population distribution for IQ scores?\nIf you sampled N = 100 IQ scores instead of N = 5, how would this impact the sampling distributions?\n\n\nExercise 4\nSuppose we get 40 students from Maynooth campus to sit through an IQ test. The test results can be found in IQ_dat.rda in the ST201 folder on the R studio server. Based on this sample, what is the 95% confidence interval for the population mean IQ?"
  },
  {
    "objectID": "9-SingleSamples.html#the-central-limit-theorem-and-the-normal-distribution",
    "href": "9-SingleSamples.html#the-central-limit-theorem-and-the-normal-distribution",
    "title": "ST201 Data Analysis",
    "section": "The Central Limit Theorem and the Normal Distribution",
    "text": "The Central Limit Theorem and the Normal Distribution\n\nFor a large enough sample size, if you take repeated samples from a population and calculate their averages, then these averages will be normally distributed.\nThis is called the central limit theorem\n\nExample\nConsider the distribution of dice rolls:\n\nPossible outcomes are 1,2,3,4,5,6 and they are all equally likely\nThe distribution is uniform\n\n\n\n\nThe mean is 3.5\nThe sd is 1.71"
  },
  {
    "objectID": "9-SingleSamples.html#the-central-limit-theorem-and-the-normal-distribution-1",
    "href": "9-SingleSamples.html#the-central-limit-theorem-and-the-normal-distribution-1",
    "title": "ST201 Data Analysis",
    "section": "The Central Limit Theorem and the Normal Distribution",
    "text": "The Central Limit Theorem and the Normal Distribution\n\nLet X be a random variable representing a dice roll.\nAssume we have 100 samples of X and the distribution looks like this\n\n\n\nset.seed(1025)\ndice_samp &lt;- sample(1:6,\n                    size = 100,\n                    replace = TRUE)\nbarplot(table(dice_samp))\n\n\n\n\n\n\n\n\n\n\n\nThe mean of the sample is 3.47\nThe sd of the sample is 1.67"
  },
  {
    "objectID": "9-SingleSamples.html#the-central-limit-theorem-and-the-normal-distribution-2",
    "href": "9-SingleSamples.html#the-central-limit-theorem-and-the-normal-distribution-2",
    "title": "ST201 Data Analysis",
    "section": "The Central Limit Theorem and the Normal Distribution",
    "text": "The Central Limit Theorem and the Normal Distribution\n\nWe know the true distribution is not normal.\nWe can see that the distribution of the samples is not normal.\nBut what does the distribution of sample means look like?\nLet’s take some 1000 random samples of dice rolls with a sample size 100 and calculate their means.\n\n\n\nsamp_means &lt;- rep(NA, 1000)\n\nfor(i in 1:1000)\n{\n  sample &lt;- sample(1:6,size = 100,replace = TRUE)\n  samp_means[i] &lt;- mean(sample)\n}\nhist(samp_means,\n     xlab = \"sample means\", \n     main = \"\")\n\n\n\n\n\n\n\n\n\n\n\nThe mean of the sample means is 3.5\nThe sd of the sample means is 0.17"
  },
  {
    "objectID": "9-SingleSamples.html#the-central-limit-theorem",
    "href": "9-SingleSamples.html#the-central-limit-theorem",
    "title": "ST201 Data Analysis",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\\[\\bar{X}\\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}})  \\text{   approximately for large n}.\\]\nUsing \\(s\\) to estimate \\(\\sigma\\): \\[\\begin{eqnarray*}\n\\bar{X} &&{\\underset{\\text{ approx}}{\\sim}}  N(\\mu, \\frac{s}{\\sqrt{n}}) \\\\\n        \\\\\n\\end{eqnarray*}\\]\nStandardising \\(\\bar{x}\\) we get:\n\\[\\begin{eqnarray*}\n\n\\frac{\\bar{X}-\\mu}{s/\\sqrt{n}}&&{\\underset{\\text{ approx}}{\\sim}} N(0,1)\n\\end{eqnarray*}\\]\n\nThe quantity \\(\\frac{s}{\\sqrt{n}}\\) is called the standard error (SE) of \\(\\bar{X}\\)."
  },
  {
    "objectID": "9-SingleSamples.html#confidence-intervals-for-mu",
    "href": "9-SingleSamples.html#confidence-intervals-for-mu",
    "title": "ST201 Data Analysis",
    "section": "Confidence intervals for \\(\\mu\\)",
    "text": "Confidence intervals for \\(\\mu\\)\nConsider that 95% of the area under the \\(N(0,1)\\) curve lies in \\(\\pm 1.96\\).\nWhat does this mean?\n\\[P(-1.96&lt;\\frac{\\bar{X}-\\mu}{s/\\sqrt{n}}&lt;1.96)=0.95\\]\nAnd,\n\\[P(\\bar{X}-1.96\\frac{s}{\\sqrt{n}}&lt;\\mu &lt;\\bar{X}+1.96\\frac{s}{\\sqrt{n}})=0.95\\]\ni.e., with probability 0.95 \\(\\mu\\) is contained in \\[\\bar{X} \\pm 1.96\\frac{s}{\\sqrt{n}}\\] which is called a 95% confidence interval for \\(\\mu\\)."
  },
  {
    "objectID": "9-SingleSamples.html#what-if-we-have-a-small-sample-size",
    "href": "9-SingleSamples.html#what-if-we-have-a-small-sample-size",
    "title": "ST201 Data Analysis",
    "section": "What if we have a small sample size?",
    "text": "What if we have a small sample size?\nIf you draw a simple random sample of size n from a population that has an approximately a normal distribution with mean \\(\\mu\\) and unknown population standard deviation \\(\\sigma\\) then\n\\[\\frac{\\bar{X}-\\mu}{s/\\sqrt{n}} \\sim t_{n-1}\\]\nThe degrees of freedom, \\(\\nu = n - 1\\), come from the calculation of the sample standard deviation s. Because the sum of the deviations is zero, we can find the last deviation once we know the other n - 1 deviations. The other n -1 deviations can change or vary freely. We call the number n - 1 the degrees of freedom (df)."
  },
  {
    "objectID": "9-SingleSamples.html#comparing-the-normal-and-t-distributions",
    "href": "9-SingleSamples.html#comparing-the-normal-and-t-distributions",
    "title": "ST201 Data Analysis",
    "section": "Comparing the normal and t-distributions",
    "text": "Comparing the normal and t-distributions\n\nThe t-distribution has “fatter tails” than the normal distribution\nBelow we see a standard normal density (i.e., X ~ N(0,1)) and overlayed is a t density with df = 5."
  },
  {
    "objectID": "9-SingleSamples.html#comparing-the-normal-and-t-distributions-1",
    "href": "9-SingleSamples.html#comparing-the-normal-and-t-distributions-1",
    "title": "ST201 Data Analysis",
    "section": "Comparing the normal and t-distributions",
    "text": "Comparing the normal and t-distributions\n\nAs the degrees of freedom increases the t-distribution tends to the normal distribution.\nBelow we see a standard normal density (i.e., X ~ N(0,1)) and overlayed is a t density with df = 40."
  },
  {
    "objectID": "9-SingleSamples.html#confidence-intervals-for-mu-1",
    "href": "9-SingleSamples.html#confidence-intervals-for-mu-1",
    "title": "ST201 Data Analysis",
    "section": "Confidence intervals for \\(\\mu\\)",
    "text": "Confidence intervals for \\(\\mu\\)\nConsider that 95% of the area under the \\(t_{n-1}\\) curve lies in \\(\\pm T_{n-1, \\alpha/2}\\).\nTherefore, \\[P(-T_{n-1, \\alpha/2}&lt;\\frac{\\bar{X}-\\mu}{s/\\sqrt{n}}&lt;T_{n-1, \\alpha/2})=0.95\\]\nAnd,\n\\[P(\\bar{X}-T_{n-1, \\alpha/2}\\frac{s}{\\sqrt{n}}&lt;\\mu &lt;\\bar{X}+T_{n-1, \\alpha/2}\\frac{s}{\\sqrt{n}})=0.95\\]\ni.e., with probability 0.95 \\(\\mu\\) is contained in \\[\\bar{X} \\pm T_{n-1, \\alpha/2}\\frac{s}{\\sqrt{n}}\\] which is called a 95% confidence interval for \\(\\mu\\)."
  },
  {
    "objectID": "9-SingleSamples.html#example",
    "href": "9-SingleSamples.html#example",
    "title": "ST201 Data Analysis",
    "section": "Example",
    "text": "Example\nA study is conducted to measure the grams of protein for a sample of energy bars. The label claims that the bars have 20 grams of protein. We want to know if the labels are correct or not.\nThe histogram of the data for 20 samples are given below:"
  },
  {
    "objectID": "9-SingleSamples.html#assessing-normality",
    "href": "9-SingleSamples.html#assessing-normality",
    "title": "ST201 Data Analysis",
    "section": "Assessing Normality",
    "text": "Assessing Normality\nVisual inspection is useful…\n\n..but subjective.\n\n\nIt’s possible to use a significance test comparing the sample distribution to a normal one in order to ascertain whether or not data show a serious deviation from normality."
  },
  {
    "objectID": "9-SingleSamples.html#assessing-normality-1",
    "href": "9-SingleSamples.html#assessing-normality-1",
    "title": "ST201 Data Analysis",
    "section": "Assessing Normality",
    "text": "Assessing Normality\nShapiro-Wilk’s method is widely recommended for normality test and it is based on the correlation between the data and the corresponding normal scores.\n\\(H_0:\\) the data come from a normal distribution\n\\(H_a:\\) the data do not come from a normal distribution\n\nshapiro.test(x)\n\n\n    Shapiro-Wilk normality test\n\ndata:  x\nW = 0.96012, p-value = 0.4169"
  },
  {
    "objectID": "9-SingleSamples.html#an-alternative-to-using-distributions",
    "href": "9-SingleSamples.html#an-alternative-to-using-distributions",
    "title": "ST201 Data Analysis",
    "section": "An Alternative to using distributions",
    "text": "An Alternative to using distributions\nConsider a situation where you want to know whether you should buy a franchise of the used car store Awesome Autos. As part of your planning, you’d like to know for how much an average car from Awesome Autos sells. In order to go through the example more clearly, let’s say that you are only able to randomly sample five cars from Awesome Auto. (If this were a real example, you would surely be able to take a much larger sample size, possibly even being able to measure the entire population!)\nBootstrapping\n\n\n\nBootstrap Example from Openintro"
  },
  {
    "objectID": "9-SingleSamples.html#an-alternative-to-using-distributions-1",
    "href": "9-SingleSamples.html#an-alternative-to-using-distributions-1",
    "title": "ST201 Data Analysis",
    "section": "An Alternative to using distributions",
    "text": "An Alternative to using distributions\nBootstrapping\n\n\ncar_data &lt;- c(18300,20100, 9600, 10700, 27000)\n\nn_samps &lt;- 1000\nbootstrap_samp_means &lt;- rep(NA, n_samps)\n\nfor(i in 1:n_samps)\n{\n  bootstrap_samp &lt;- sample(car_data, replace = TRUE)\n  bootstrap_samp_means[i] &lt;- mean(bootstrap_samp)\n}\n\nhist(bootstrap_samp_means)\n\n\n\n\n\n\n\n\n\n\n\nThe histogram summarizes one thousand bootstrap samples of the bootstrap sample means.\nThe bootstrapped average car prices vary from about $10,000 to $25,000.\nThe bootstrap percentile confidence interval is found by locating the middle 90% (for a 90% confidence interval) or a 95% (for a 95% confidence interval) of the bootstrapped means.\n\n\n\n\n\nquantile(bootstrap_samp_means, c(0.025,0.975))\n\n\n 2.5% 97.5% \n12000 22360"
  },
  {
    "objectID": "10-tests.html#hypothesis-tests",
    "href": "10-tests.html#hypothesis-tests",
    "title": "ST201 Data Analysis",
    "section": "Hypothesis Tests",
    "text": "Hypothesis Tests\nOnce an analyst estimates the parameters on the basis of a random sample, they would like to infer something about the value of the parameter in the population. Statistical hypothesis tests facilitate the comparison of estimated values with hypothetical values.\nExample\nA clinical study is conducted to compare the effectiveness of a new drug (B) to an established standard drug (A) for high blood pressure.\n\nAssume that, as a first step, we want to find out whether the new drug causes a higher reduction in blood pressure than the already established older drug.\nA possible hypothesis is that the average change in the blood pressure in group B is higher than in group A."
  },
  {
    "objectID": "10-tests.html#one--and-two-sample-problems",
    "href": "10-tests.html#one--and-two-sample-problems",
    "title": "ST201 Data Analysis",
    "section": "One- and Two-Sample Problems",
    "text": "One- and Two-Sample Problems\nIn one-sample problems, the data is usually assumed to arise as one sample from a defined population. In two-sample problems, the data originates in the form of two samples possibly from two different populations.\nFor an unknown population parameter (e.g., \\(\\mu\\)) and a fixed value (e.g. \\(\\mu_0\\)), the following three cases have to be distinguished:\n\n\n\nCase\n\\(H_0\\)\n\\(H_a\\)\nType\n\n\n\n\n(a)\n\\(\\mu = \\mu_0\\)\n\\(\\mu \\neq \\mu_0\\)\n2-sided\n\n\n(b)\n\\(\\mu \\geq \\mu_0\\)\n\\(\\mu &lt; \\mu_0\\)\n1-sided\n\n\n(c)\n\\(\\mu \\leq \\mu_0\\)\n\\(\\mu &gt; \\mu_0\\)\n1-sided"
  },
  {
    "objectID": "10-tests.html#one-sample-problem-when-the-variance-is-unknown",
    "href": "10-tests.html#one-sample-problem-when-the-variance-is-unknown",
    "title": "ST201 Data Analysis",
    "section": "One sample problem when the variance is unknown",
    "text": "One sample problem when the variance is unknown\nNow that we have used the t-distribution for making a confidence interval for a mean, we can consider hypothesis tests for the mean.\nIf the population variance \\(\\sigma^2\\) is unknown (which is most often the case in practice), hypotheses about the mean \\(\\mu\\) of a normal random variable \\(X \\sim N(\\mu, \\sigma^2)\\) can be tested. The unknown variance is estimated from the sample.\n\n\n\n\n\n\nThe test statistic for assessing a single mean.\n\n\nThe \\(T\\) score is a ratio of how the sample mean differs from the hypothesized mean as compared to how the observations vary.\nThe test statistic is therefore\n\\[T_{stat} = \\frac{\\bar{X}-\\mu_0}{s/\\sqrt{n}} \\]\nWhen the null hypothesis is true and the conditions are met, T has a t-distribution with \\(df = n-1\\)\n\\[T_{stat} \\sim t_{n-1}\\]\nConditions:\n\nIndependent observations.\nLarge samples and no extreme outliers."
  },
  {
    "objectID": "10-tests.html#critical-regions-and-test-decisions",
    "href": "10-tests.html#critical-regions-and-test-decisions",
    "title": "ST201 Data Analysis",
    "section": "Critical regions and test decisions",
    "text": "Critical regions and test decisions\nRules to make test decisions for the one-sample t-test\n\n\n\n\n\nCase\n\\(H_0\\)\n\\(H_a\\)\nType\n\n\n\n\n(a)\n\\(\\mu = \\mu_0\\)\n\\(\\mu \\neq \\mu_0\\)\n2-sided\n\n\n(b)\n\\(\\mu \\geq \\mu_0\\)\n\\(\\mu &lt; \\mu_0\\)\n1-sided (left)\n\n\n(c)\n\\(\\mu \\leq \\mu_0\\)\n\\(\\mu &gt; \\mu_0\\)\n1-sided (right)"
  },
  {
    "objectID": "10-tests.html#sleep-example",
    "href": "10-tests.html#sleep-example",
    "title": "ST201 Data Analysis",
    "section": "Sleep Example",
    "text": "Sleep Example\nA study is conducted to see if the student populations gets on average 8 hours of sleep.\nSuppose a random sample of size n = 20 has a mean of \\(\\bar{x}\\) = 6.75 and a sample standard deviation of \\(\\sigma\\) = 2.40.\nTest whether the average hours of sleep differs from 8.\n\n\n\n\n\n\n\n\n\n\n\n\nWhere does Tstat lie?"
  },
  {
    "objectID": "10-tests.html#comparing-the-means-of-two-independent-samples",
    "href": "10-tests.html#comparing-the-means-of-two-independent-samples",
    "title": "ST201 Data Analysis",
    "section": "Comparing the Means of Two Independent Samples",
    "text": "Comparing the Means of Two Independent Samples\nIn a two-sample problem, we may be interested in comparing the means of two independent samples. Assume that we have two samples of two normally distributed variables \\(X \\sim N(\\mu_x, \\sigma_x^2)\\) and \\(Y \\sim N(\\mu_y, \\sigma_y^2)\\) of size n and m.\nWe can specify the following hypotheses:\n\n\n\nCase\n\\(H_0\\)\n\\(H_a\\)\nType\n\n\n\n\n(a)\n\\(\\mu_x = \\mu_y\\)\n\\(\\mu_x \\neq \\mu_y\\)\n2-sided\n\n\n(b)\n\\(\\mu_x \\geq \\mu_y\\)\n\\(\\mu_x &lt; \\mu_y\\)\n1-sided\n\n\n(c)\n\\(\\mu_x \\leq \\mu_y\\)\n\\(\\mu_x &gt; \\mu_y\\)\n1-sided\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe will consider two cases."
  },
  {
    "objectID": "10-tests.html#the-variances-are-unknown-but-equal-two-sample-t-test.",
    "href": "10-tests.html#the-variances-are-unknown-but-equal-two-sample-t-test.",
    "title": "ST201 Data Analysis",
    "section": "The variances are unknown, but equal (two-sample t-test).",
    "text": "The variances are unknown, but equal (two-sample t-test).\nIf we have assumed that both populations have the same variance \\(\\sigma^2\\).\n\nWe can estimate this from either \\(s_X\\) and \\(s_Y\\).\nHowever, it would be better to use both to estimate \\(\\sigma^2\\).\nWe `pool’ these two statistics into an overall estimate of \\(\\sigma^2\\):\n\n\\[s_p^2=\\frac{(n-1)s_X^2+(m-1)s_Y^2}{n+m-2}.\\]\nThe test statistic in this case\n\\[T_{stat} = \\frac{\\bar{X}-\\bar{Y}}{s_p \\sqrt{\\frac{1}{n}+\\frac{1}{m}}} \\sim t_{n + m-2}\\]\nwhere \\(T_{stat}\\) follows a t-distribution with n + m - 2 degrees of freedom if \\(H_0\\) is true.\nConditions:\n\nIndependent observations.\nLarge samples and no extreme outliers."
  },
  {
    "objectID": "10-tests.html#the-variances-are-unknown-and-unequal-welch-test.",
    "href": "10-tests.html#the-variances-are-unknown-and-unequal-welch-test.",
    "title": "ST201 Data Analysis",
    "section": "The variances are unknown and unequal (Welch test).",
    "text": "The variances are unknown and unequal (Welch test).\nThe test statistic in this case\n\\[T_{stat} = \\frac{\\bar{X}-\\bar{Y}}{\\sqrt{\\frac{s_x^2}{n}+\\frac{s_y^2}{m}}} \\sim t_{\\nu}\\]\nwhere \\(T_{stat}\\) follows a t-distribution with \\(\\nu\\) degrees of freedom if \\(H_0\\) is true and\n\\[\\nu = \\bigg(\\frac{s_x^2}{n} + \\frac{s_y^2}{m}\\bigg)^2/ \\bigg( \\frac{(\\frac{s_x^2}{n})^2}{n-1} + \\frac{(\\frac{s_y^2}{m})^2}{m-1}\\bigg)\\]\nConditions:\n\nIndependent observations.\nLarge samples and no extreme outliers."
  },
  {
    "objectID": "10-tests.html#example",
    "href": "10-tests.html#example",
    "title": "ST201 Data Analysis",
    "section": "Example",
    "text": "Example\nEvery year, the US releases to the public a large dataset containing information on births recorded in the country. This dataset has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. We will work with a random sample of 1,000 cases from the dataset released in 2014.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfage\nmage\nmature\nweeks\npremie\nvisits\ngained\nweight\nlowbirthweight\nsex\nhabit\nmarital\nwhitemom\n\n\n\n\n34\n34\nyounger mom\n37\nfull term\n14\n28\n6.96\nnot low\nmale\nnonsmoker\nmarried\nwhite\n\n\n36\n31\nyounger mom\n41\nfull term\n12\n41\n8.86\nnot low\nfemale\nnonsmoker\nmarried\nwhite\n\n\n37\n36\nmature mom\n37\nfull term\n10\n28\n7.51\nnot low\nfemale\nnonsmoker\nmarried\nnot white\n\n\nNA\n16\nyounger mom\n38\nfull term\nNA\n29\n6.19\nnot low\nmale\nnonsmoker\nnot married\nwhite\n\n\n32\n31\nyounger mom\n36\npremie\n12\n48\n6.75\nnot low\nfemale\nnonsmoker\nmarried\nwhite"
  },
  {
    "objectID": "10-tests.html#analysis-question",
    "href": "10-tests.html#analysis-question",
    "title": "ST201 Data Analysis",
    "section": "Analysis Question",
    "text": "Analysis Question\nWe would like to know, is there convincing evidence that newborns from mothers who smoke have a different average birth weight than newborns from mothers who do not smoke?\n\n\n\n\n\n\nThe Hypothesis\n\n\nSet up appropriate hypotheses to evaluate whether there is a relationship between a mother smoking and average birth weight.\nThe null hypothesis represents the case of no difference between the groups.\n\\(H_o: \\mu_x = \\mu_y\\) There is no difference in average birth weight for newborns from mothers who did and did not smoke.\n\\(H_a: \\mu_x \\neq \\mu_y\\) There is some difference in average newborn weights from mothers who did and did not smoke.\n\n\n\nSample Statistics\n\n\n      habit weight.mean weight.sd\n1 nonsmoker    7.269873  1.232846\n2    smoker    6.677193  1.596645"
  },
  {
    "objectID": "10-tests.html#variability",
    "href": "10-tests.html#variability",
    "title": "ST201 Data Analysis",
    "section": "Variability",
    "text": "Variability\nWe check the two conditions necessary to model the difference in sample means using the t-distribution.\nBecause the data come from a simple random sample, the observations are independent, both within and between samples.\nWith both groups over 30 observations, we inspect the data for any particularly extreme outliers\n\nSince both conditions are satisfied, the difference in sample means may be modeled using a t-distribution."
  },
  {
    "objectID": "10-tests.html#results",
    "href": "10-tests.html#results",
    "title": "ST201 Data Analysis",
    "section": "Results",
    "text": "Results\n\\(\\bar{x_1} - \\bar{x_2} = 0.59\\), \\(SE = 0.16\\), the sample sizes are \\(n_1 = 867\\) and \\(n_2 = 114\\) and \\(df = 131\\).\nWe can find the test statistic for this test using:\n\\[Tstat = \\frac{0.59 - 0}{0.16} = 3.82\\]"
  },
  {
    "objectID": "10-tests.html#results-1",
    "href": "10-tests.html#results-1",
    "title": "ST201 Data Analysis",
    "section": "Results",
    "text": "Results\n\n\n# Perform a t-test to compare the means of 'value' between 'category' A and B\nt_test_result &lt;- t.test(weight ~ habit, \n                        data = births14)\n\n# View the result of the t-test\nprint(t_test_result)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight by habit\nt = 3.8166, df = 131.31, p-value = 0.0002075\nalternative hypothesis: true difference in means between group nonsmoker and group smoker is not equal to 0\n95 percent confidence interval:\n 0.2854852 0.8998751\nsample estimates:\nmean in group nonsmoker    mean in group smoker \n               7.269873                6.677193 \n\n\n\nThe p-value is smaller than the confidence level, 0.05, so we reject the null hypothesis. The data provide statistical evidence of a difference in the average weights of babies born to mothers who smoked during pregnancy and those who did not."
  },
  {
    "objectID": "10-tests.html#confidence-intervals-for-mu_x---mu_y",
    "href": "10-tests.html#confidence-intervals-for-mu_x---mu_y",
    "title": "ST201 Data Analysis",
    "section": "Confidence intervals for \\(\\mu_x - \\mu_y\\)",
    "text": "Confidence intervals for \\(\\mu_x - \\mu_y\\)\n\nLet \\(\\mu_d = \\mu_x - \\mu_y\\)\n95% of the area under the \\(t_{\\nu}\\) curve lies in \\(\\pm T_{\\nu, \\alpha/2}\\).\n\nTherefore, \\[P(-T_{\\nu, \\alpha/2}&lt;\\frac{(\\bar{X}-\\bar{Y}) - \\mu_d}{SE}&lt;T_{\\nu, \\alpha/2})=0.95\\]\nAnd,\n\\[P((\\bar{X} - \\bar{Y})-T_{\\nu, \\alpha/2}*SE&lt;\\mu_d &lt;(\\bar{X} - \\bar{Y})+T_{\\nu, \\alpha/2}*SE)=0.95\\]\ni.e. with probability 0.95 \\(\\mu_d\\) is contained in \\[(\\bar{X} - \\bar{Y}) \\pm T_{\\nu, \\alpha/2}*SE\\] which is called a 95% confidence interval for \\(\\mu_d\\)."
  },
  {
    "objectID": "10-tests.html#class-example",
    "href": "10-tests.html#class-example",
    "title": "ST201 Data Analysis",
    "section": "Class Example",
    "text": "Class Example\nWe would like to find out the effect of a new drug on blood pressure. Patients with high blood pressure were randomly assigned into two groups, a placebo group and a treatment group. The placebo group received conventional treatment while the treatment group received a new drug that is expected to lower blood pressure. After treatment for a couple of months, the two-sample t test is used to compare the average blood pressure of the two groups. Note that each patient is measured once and belongs to one group.\n\n\n\n\n\n\nplacebo\n90\n95\n67\n120\n89\n92\n100\n82\n79\n85\n\n\ntreatment\n71\n79\n69\n98\n91\n85\n89\n75\n78\n80\n\n\n\n\n\nWe want to test whether drug reduces blood pressure."
  },
  {
    "objectID": "10-tests.html#hypothesis-tests-for-means---one-sample-problems",
    "href": "10-tests.html#hypothesis-tests-for-means---one-sample-problems",
    "title": "ST201 Data Analysis",
    "section": "Hypothesis Tests for Means - One-Sample Problems",
    "text": "Hypothesis Tests for Means - One-Sample Problems\nStatistical hypothesis tests facilitate the comparison of estimated values with hypothetical values.\nIn one-sample problems, the data is usually assumed to arise as one sample from a defined population. In two-sample problems, the data originates in the form of two samples possibly from two different populations (more on this later).\nFor an unknown population parameter (e.g., \\(\\mu\\)) and a fixed value (e.g. \\(\\mu_0\\)), the following three cases have to be distinguished:\n\n\n\nCase\n\\(H_0\\)\n\\(H_a\\)\nType\n\n\n\n\n(a)\n\\(\\mu = \\mu_0\\)\n\\(\\mu \\neq \\mu_0\\)\n2-sided\n\n\n(b)\n\\(\\mu \\geq \\mu_0\\)\n\\(\\mu &lt; \\mu_0\\)\n1-sided\n\n\n(c)\n\\(\\mu \\leq \\mu_0\\)\n\\(\\mu &gt; \\mu_0\\)\n1-sided"
  },
  {
    "objectID": "10-tests.html#results-in-r",
    "href": "10-tests.html#results-in-r",
    "title": "ST201 Data Analysis",
    "section": "Results in R",
    "text": "Results in R\n\n\n# Perform a t-test to compare the mean to 8\nt_test_result &lt;- t.test(student_sleep, mu = 8)\n\n# View the result of the t-test\nprint(t_test_result)\n\n\n\n    One Sample t-test\n\ndata:  student_sleep\nt = -2.8297, df = 19, p-value = 0.01071\nalternative hypothesis: true mean is not equal to 8\n95 percent confidence interval:\n 5.738455 7.661545\nsample estimates:\nmean of x \n      6.7 \n\n\n\nThe p-value is smaller than the confidence level, 0.05, so we reject the null hypothesis. The data provide statistical evidence that the average hours of sleep is different from 8."
  },
  {
    "objectID": "10-tests.html#results-in-r-1",
    "href": "10-tests.html#results-in-r-1",
    "title": "ST201 Data Analysis",
    "section": "Results in R",
    "text": "Results in R\n\n# Perform a t-test to compare the means of 'value' between 'category' A and B\nt_test_result &lt;- t.test(weight ~ habit, \n                        data = births14)\n\n# View the result of the t-test\nprint(t_test_result)\n\n\n    Welch Two Sample t-test\n\ndata:  weight by habit\nt = 3.8166, df = 131.31, p-value = 0.0002075\nalternative hypothesis: true difference in means between group nonsmoker and group smoker is not equal to 0\n95 percent confidence interval:\n 0.2854852 0.8998751\nsample estimates:\nmean in group nonsmoker    mean in group smoker \n               7.269873                6.677193 \n\n\n\nThe p-value is smaller than the confidence level, 0.05, so we reject the null hypothesis. The data provide statistical evidence of a difference in the average weights of babies born to mothers who smoked during pregnancy and those who did not."
  },
  {
    "objectID": "11-SLR.html#correlation",
    "href": "11-SLR.html#correlation",
    "title": "ST201 Data Analysis",
    "section": "Correlation",
    "text": "Correlation\nCorrelation is defined as\n\\[Cor(X, Y ) = \\frac{\\sum_{i=1}^n (xi - \\bar{x})(yi - \\bar{y})}{\\sqrt{\\sum_{i=1}^n(xi - \\bar{x})^2} \\sqrt{\\sum_{i = 1}^n(yi - \\bar{y})^2}}\\]\nis a measure of the linear relationship between X and Y.\n\nCorrelation tells you about the direction and strength of the linear relationship but it does not imply a causal relationship.\nCorrelation takes on values in the range [-1,1]\nCorrelation cannot be used to predict \\(Y\\) based on values of \\(X\\)."
  },
  {
    "objectID": "11-SLR.html#simple-linear-regression",
    "href": "11-SLR.html#simple-linear-regression",
    "title": "ST201 Data Analysis",
    "section": "Simple Linear Regression",
    "text": "Simple Linear Regression\nSimple linear regression is a very straightforward approach for predicting a quantitative response Y on the basis of a single predictor variable X.\n\nIt assumes that there is approximately a linear relationship between X and Y.\nMathematically, we can write this linear relationship as\n\n\\[Y \\approx \\beta_0 + \\beta_1X\\]\nBased on the relationship between \\(X\\) and \\(Y\\) data, we will have some uncertainty regarding our estimates of the model parameters \\(\\beta_0\\) and \\(\\beta_1\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor instance, we might wonder, should we move the line up or down a little, or should we tilt it more or less?"
  },
  {
    "objectID": "11-SLR.html#example",
    "href": "11-SLR.html#example",
    "title": "ST201 Data Analysis",
    "section": "Example",
    "text": "Example\nAs an example, assume we have data where X represents TV advertising and Y represent sales, in n = 200 different markets.\n\nThen we can regress sales onto TV by fitting the model\n\\[sales \\approx \\beta_0 + \\beta_1TV\\]\n\n\\(\\beta_0\\) and \\(\\beta_1\\) are two unknown constants that represent the intercept and slope terms in the linear model.\nThese are known as the model coefficients or parameters.\nOnce we produce estimates of \\(\\beta_0\\) and \\(\\beta_1\\) we can predict future sales on the basis of a particular value of TV advertising by computing\n\n\\[\\widehat{y} =  \\widehat{\\beta}_0 + \\widehat{\\beta}_1x\\]\n\nwhere \\(\\widehat{y}\\) indicates a prediction of Y on the basis of X = x."
  },
  {
    "objectID": "11-SLR.html#estimating-the-parameters",
    "href": "11-SLR.html#estimating-the-parameters",
    "title": "ST201 Data Analysis",
    "section": "Estimating the parameters",
    "text": "Estimating the parameters\n\n\\(\\beta_0\\) and \\(\\beta_1\\) are unknown so we must use data to estimate them. Let\n\n\\[(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\] represent n observation pairs, each of which consists of a measurement of X and a measurement of Y .\n\nIn the Advertising example, this data set consists of the TV advertising budget and product sales in n = 200 different markets.\nOur goal is to obtain coefficient estimates \\(\\widehat{\\beta}_0\\) and \\(\\widehat{\\beta}_1\\) such that the linear model fits the available data closely.\nThere are a number of ways of measuring closeness. However, by far the most common approach involves minimizing the sum of squared errors."
  },
  {
    "objectID": "11-SLR.html#estimating-the-parameters-1",
    "href": "11-SLR.html#estimating-the-parameters-1",
    "title": "ST201 Data Analysis",
    "section": "Estimating the parameters",
    "text": "Estimating the parameters\n\nThe best model fit for the data is found by minimizing the sum of squared errors.\nThe residuals (errors) are the leftover variation in the data after accounting for the model fit:\n\n\\[Data = Fit + Residual\\]\n\nEach grey line segment represents an error, and the fit is found by making a compromise that involves averaging the squared errors."
  },
  {
    "objectID": "11-SLR.html#estimating-the-parameters-2",
    "href": "11-SLR.html#estimating-the-parameters-2",
    "title": "ST201 Data Analysis",
    "section": "Estimating the parameters",
    "text": "Estimating the parameters\n\nWe assume that the true relationship between X and Y takes the form \\(Y = f(X) + \\epsilon\\) for some unknown function \\(f\\), where \\(\\epsilon\\) is a mean-zero random error term.\nIf \\(f\\) is to be approximated by a simple linear function, then we can write this relationship as\n\n\\[Y = \\beta_0 + \\beta_1X + \\epsilon\\]\n\nThe error term is a catch-all for what we miss with this simple model: the true relationship is probably not linear, there may be other variables that cause variation in Y.\nLet \\(\\widehat{y_i} = \\widehat{\\beta}_0 + \\widehat{\\beta}_1x_i\\) be the prediction for \\(y_i\\) based on \\(x_i\\)\nThen \\(e_i = y_i - \\widehat{y}_i\\) represents the ith residual (error)\nWe define the residual sum of squares (RSS) as\n\n\\[RSS = e_1^2 + e_2^2 + \\ldots + e_n^2\\]\n\nThe least squares approach chooses \\(\\widehat{\\beta}_0\\) and \\(\\widehat{\\beta}_1\\) to minimize the RSS."
  },
  {
    "objectID": "11-SLR.html#assessing-the-accuracy-of-the-coefficient-estimates",
    "href": "11-SLR.html#assessing-the-accuracy-of-the-coefficient-estimates",
    "title": "ST201 Data Analysis",
    "section": "Assessing the Accuracy of the Coefficient Estimates",
    "text": "Assessing the Accuracy of the Coefficient Estimates\nWe will consider the analogy with the estimation of the population mean \\(\\mu\\) of a random variable Y .\n\nA natural question is as follows: how accurate is the sample mean \\(\\widehat{\\mu}\\) (\\(\\bar{x}\\)) as an estimate of \\(\\mu\\)?\nWe have established that the average of \\(\\widehat{\\mu}\\)’s over many sample data sets will be very close to \\(\\mu\\) (CLT)\nBut how far off will a single estimate of \\(\\widehat{\\mu}\\) be?\nIn general, we answer this question by computing the standard error of \\(\\widehat{\\mu}\\) with the formula\n\\[SE = \\frac{s}{\\sqrt{n}}\\]"
  },
  {
    "objectID": "11-SLR.html#assessing-the-accuracy-of-the-coefficient-estimates-1",
    "href": "11-SLR.html#assessing-the-accuracy-of-the-coefficient-estimates-1",
    "title": "ST201 Data Analysis",
    "section": "Assessing the Accuracy of the Coefficient Estimates",
    "text": "Assessing the Accuracy of the Coefficient Estimates\n\nStandard errors can also be computed for regression parameters\nThen once we have standard errors, they can be used to compute confidence intervals.\nThe 95% confidence interval for \\(\\beta_1\\) approximately takes the form\n\n\\[\\widehat{\\beta}_1 \\pm T_{1-\\alpha/2, df}*SE(\\widehat{\\beta}_1)\\]\n\nSimilarly, a confidence interval for \\(\\beta_0\\) approximately takes the form\n\n\\[\\widehat{\\beta}_0 \\pm T_{1-\\alpha/2, df}*SE(\\widehat{\\beta}_0)\\]"
  },
  {
    "objectID": "11-SLR.html#significance-testing-for-the-coefficient-estimates",
    "href": "11-SLR.html#significance-testing-for-the-coefficient-estimates",
    "title": "ST201 Data Analysis",
    "section": "Significance Testing for the Coefficient Estimates",
    "text": "Significance Testing for the Coefficient Estimates\n\nWe’ve seen that standard errors can also be used to perform hypothesis tests.\nFor linear regression we can test\n\n\\[H_0 : \\beta_1 = 0\\] versus \\[H_a : \\beta_1 \\neq 0\\]\n\nIf the data do not provide evidence against \\(\\beta_1 = 0\\) then the model reduces to \\(Y = \\beta_0 + \\epsilon\\), and X is not linearly associated with Y."
  },
  {
    "objectID": "11-SLR.html#model-fit",
    "href": "11-SLR.html#model-fit",
    "title": "ST201 Data Analysis",
    "section": "Model Fit",
    "text": "Model Fit\n\nOnce we tested for the significance \\(\\beta_1\\), it is natural to want to quantify the extent to which the model fits the data.\nThe quality of a linear regression fit is typically assessed using two related quantities\n\nthe residual standard error (RSE) and\nthe \\(R^2\\) statistic."
  },
  {
    "objectID": "11-SLR.html#the-residual-standard-error-rse",
    "href": "11-SLR.html#the-residual-standard-error-rse",
    "title": "ST201 Data Analysis",
    "section": "The Residual Standard Error (RSE)",
    "text": "The Residual Standard Error (RSE)\n\nThe RSE is an estimate of the standard deviation of \\(\\epsilon\\). Roughly speaking, it is the average amount that the response will deviate from the true regression line. It is computed using the formula\n\n\\[RSE = \\sqrt{\\frac{1}{n-2}RSS}\\]\n\nThe RSE is considered a measure of the lack of fit of the model to the data.\nIf the predictions obtained using the model are very close to the true outcome values the RSE will be small, and we can conclude that the model fits the data very well."
  },
  {
    "objectID": "11-SLR.html#the-r2-statistic",
    "href": "11-SLR.html#the-r2-statistic",
    "title": "ST201 Data Analysis",
    "section": "The R\\(^2\\) Statistic",
    "text": "The R\\(^2\\) Statistic\n\nThe RSE provides an absolute measure of lack of fit of the model to the data. But since it is measured in the units of Y , it is not always clear what constitutes a good RSE.\nThe R\\(^2\\) statistic provides an alternative measure of fit. It takes the form of a proportion\nspecifically the proportion of the variation in Y that is explained by X\ngiven that it is a proportion it always takes on a value between 0 and 1, and is therefore independent of the scale of Y.\nTo calculate R\\(^2\\), we use the formula\n\n\\[R^2 = \\frac{TSS - RSS}{TSS}\\]\nwhere \\(TSS = \\sum (y_i - \\bar{y})^2\\) is the total sum of squares."
  },
  {
    "objectID": "11-SLR.html#checking-model-assumptions",
    "href": "11-SLR.html#checking-model-assumptions",
    "title": "ST201 Data Analysis",
    "section": "Checking Model Assumptions",
    "text": "Checking Model Assumptions\nWith linear regression we are making an obvious assumption that the response/predictor relationship is linear.\nThe other assumptions made for the linear model mostly relate to the error terms:\n\\[e_i \\sim N(0, \\sigma^2)\\].\n\nThis implies a few things\n\nthe difference between \\(y_i\\) and \\(\\widehat{y_i}\\) (which is e_i) needs to follow a normal distribution\nthe variance for each error \\(e_i\\) is constant as \\(\\sigma^2\\)\nthere is no correlation between the error terms (i.e., they are independent)"
  },
  {
    "objectID": "11-SLR.html#checking-model-assumptions-1",
    "href": "11-SLR.html#checking-model-assumptions-1",
    "title": "ST201 Data Analysis",
    "section": "Checking Model Assumptions",
    "text": "Checking Model Assumptions\nWe can look at a number of plots to check if error assumptions are valid.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Residual Plots"
  },
  {
    "objectID": "11-SLR.html#simple-linear-regression-in-r",
    "href": "11-SLR.html#simple-linear-regression-in-r",
    "title": "ST201 Data Analysis",
    "section": "Simple Linear Regression in R",
    "text": "Simple Linear Regression in R\n\nAdvertising &lt;- read_csv(\"Advertising.csv\")\n\nlr_mod &lt;- lm(sales ~ TV, data = Advertising)\nlr_mod\n\n\nCall:\nlm(formula = sales ~ TV, data = Advertising)\n\nCoefficients:\n(Intercept)           TV  \n    7.03259      0.04754  \n\nsummary(lr_mod)\n\n\nCall:\nlm(formula = sales ~ TV, data = Advertising)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.3860 -1.9545 -0.1913  2.0671  7.2124 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***\nTV          0.047537   0.002691   17.67   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.259 on 198 degrees of freedom\nMultiple R-squared:  0.6119,    Adjusted R-squared:  0.6099 \nF-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "11-SLR.html#class-example",
    "href": "11-SLR.html#class-example",
    "title": "ST201 Data Analysis",
    "section": "Class Example",
    "text": "Class Example\nThe whoop fitness tracker takes measurements related to recovery, strain and sleep. The dataset whoop_data contains 31 days of data on sleep performance, heart rate variability (hrv), activity strain and recovery.\nHave a look at the data set and see which variable appears to have the strongest predictive relationship with recovery. Fit a linear regression model using the chosen predictor variable and interpret the output."
  }
]